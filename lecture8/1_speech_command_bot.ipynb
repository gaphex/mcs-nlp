{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this seminar we will build a bot which will be able to process voice commands using Google Speech Recognition and our brain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sadly, Telegram records voice in OGG format, while GSR works with WAV-encoded data. We will need to convert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Download and install ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Ubuntu users (easy mode):\n",
    "* `sudo apt-get update`\n",
    "* `sudo apt-get install ffmpeg`\n",
    "* make sure you can run `ffmpeg` from your console"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Mac users:\n",
    "* download binaries from https://ffmpeg.zeranoe.com/builds/macos64/static/ffmpeg-3.4-macos64-static.zip\n",
    "* unzip somewhere\n",
    "* find a full path to ffmpeg executable which will look like `/path_to_your_unzip_dir/ffmpeg-3.4-macos64-static/bin/ffmpeg`\n",
    "* e.g. on my PC it's `/Users/denisantyukhov/Downloads/ffmpeg-3.4-macos64-static/bin/ffmpeg`\n",
    "* set `FFMPEG_PATH` in `config.py` to your correct path so that it looks like\n",
    "\n",
    "`FFMPEG_PATH = '/Users/denisantyukhov/Downloads/ffmpeg-3.4-macos64-static/bin/ffmpeg'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Windows users:\n",
    "* download binaries from https://ffmpeg.zeranoe.com/builds/win64/static/ffmpeg-3.4-win64-static.zip (64 bit)\n",
    "* unzip somewhere\n",
    "* find a full path to ffmpeg executable which will probably look like `C:\\your_folder\\ffmpeg-3.4-win64-static\\bin\\ffmpeg.exe`\n",
    "* set `FFMPEG_PATH` in `config.py` to your correct path so that it looks like\n",
    "\n",
    "`FFMPEG_PATH=r'C:\\ffmpeg-3.4-win64-static\\bin\\ffmpeg.exe'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Configure your bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just set the TOKEN variable with the token that BOT FATHER gave you during lecture 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Configure Google Speech Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `gsr_config.yml` set the `KEY` variable with the token you recieved in Slack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Install dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pip install -r requirements.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Check that it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from speech2text import speech2text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = speech2text(\"check.ogg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r)\n",
    "assert r == 'проверка микрофона'\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Run your bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import logging\n",
    "import telegram\n",
    "\n",
    "from telegram.ext import Updater, CommandHandler, MessageHandler, Filters\n",
    "\n",
    "from speech2text import speech2text\n",
    "from config import TOKEN, LOG_FILE, DL_DIR\n",
    "\n",
    "\n",
    "# Enable logging\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# Logging to file\n",
    "fh = logging.FileHandler(LOG_FILE)\n",
    "fh.setLevel(logging.DEBUG)\n",
    "fh.setFormatter(formatter)\n",
    "# Logging to console\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.DEBUG)\n",
    "ch.setFormatter(formatter)\n",
    "\n",
    "logger.addHandler(fh)\n",
    "logger.addHandler(ch)\n",
    "\n",
    "\n",
    "class Bot:\n",
    "    def __init__(self):\n",
    "\n",
    "        self.updater = Updater(TOKEN)\n",
    "        self.dsp = self.updater.dispatcher\n",
    "\n",
    "        # register handler functions which define how the bot reacts to events\n",
    "        self.dsp.add_handler(CommandHandler(\"start\", get_help))\n",
    "        self.dsp.add_handler(CommandHandler(\"help\", get_help))\n",
    "        self.dsp.add_handler(MessageHandler(Filters.text, echo))\n",
    "        self.dsp.add_handler(MessageHandler(Filters.voice, process_audio))\n",
    "        Filters.audio\n",
    "        self.dsp.add_error_handler(error)\n",
    "\n",
    "        logger.info('Im alive!')\n",
    "\n",
    "    def power_on(self):\n",
    "        # start the Bot\n",
    "        self.updater.start_polling()\n",
    "        self.updater.idle()\n",
    "\n",
    "def echo(bot, update):\n",
    "    logger.info('echo recieved message: {}'.format(update.message.text))\n",
    "    bot.sendMessage(update.message.chat_id, text=update.message.text)\n",
    "\n",
    "\n",
    "def error(bot, update, error):\n",
    "    # all uncaught telegram-related exceptions will be rerouted here\n",
    "    logger.error('Update \"%s\" caused error \"%s\"' % (update, error))\n",
    "\n",
    "\n",
    "def get_help(bot, update):\n",
    "    logger.info('get_help recieved message: {}'.format(update.message.text))\n",
    "    help_msg = ('Greetings, {} {}! Name is {}, at your service.\\n'\n",
    "                'My purpose is to demonstrate how ').format(\n",
    "        update.message.from_user.first_name, update.message.from_user.last_name, bot.name)\n",
    "    bot.sendMessage(update.message.chat_id, text=help_msg)\n",
    "    \n",
    "    \n",
    "def process_audio(bot, update):\n",
    "    logger.info('process_audio recieved: {}'.format(''))\n",
    "    loop = asyncio.new_event_loop()\n",
    "    asyncio.set_event_loop(loop)\n",
    "    try:\n",
    "\n",
    "        voice_file_id = update.message.voice.file_id\n",
    "        voice_file = bot.get_file(voice_file_id)\n",
    "        ogg_fname = \"{}/{}\".format(DL_DIR, \"voice.ogg\")\n",
    "        voice_file.download(ogg_fname)\n",
    "        logger.info('downloaded')\n",
    "        transcript = speech2text(ogg_fname)\n",
    "        logger.info('transcription result: {}'.format(transcript))\n",
    "        bot.sendMessage(update.message.chat_id, text=transcript)\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(e)\n",
    "\n",
    "my_bot = Bot()\n",
    "my_bot.power_on()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make our bot do something useful with our voice commands. Some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import get_rates, get_weather, get_anekdot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_rates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_weather())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_anekdot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, define an object that will return the most probable action for out requst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import scipy\n",
    "import pymystem3\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feel free to modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ENGINE_3(object):\n",
    "    def __init__(self, kbase):\n",
    "        self.knowledge_base = kbase\n",
    "        self.lemmatizer = pymystem3.Mystem()\n",
    "        \n",
    "        # contains correct output for each class\n",
    "        self.answers = np.array([t['answer'] for t in self.knowledge_base])\n",
    "        self.vectorizer = self.prepare_vectorizer()\n",
    "        self.vectorized_kbase, self.class_indexes = self.vectorize_knowledge_base()\n",
    "        \n",
    "    def prepare_vectorizer(self):\n",
    "        \"\"\"\n",
    "        Fits TF-IDF vectorizer using all available text from self.knowledge_base\n",
    "        Returns TF-IDF vectorizer object\n",
    "        \"\"\"\n",
    "        vectorizer = TfidfVectorizer(ngram_range=(1,2), tokenizer=self.tokenize_and_lemmatize)\n",
    "        all_texts = []\n",
    "        for kb in self.knowledge_base:\n",
    "            all_texts.append(kb['question'])\n",
    "            all_texts += kb['paraphrased_questions']\n",
    "        vectorizer.fit(all_texts)\n",
    "        return vectorizer\n",
    "    \n",
    "    def vectorize(self, data):\n",
    "        \"\"\"\n",
    "        Turns a list of N strings into their vector representation using self.vectorizer.\n",
    "        Returns a a matrix of shape [N, n_features]\n",
    "        \"\"\"\n",
    "        return self.vectorizer.transform(data)\n",
    "        \n",
    "    def vectorize_knowledge_base(self):\n",
    "        \"\"\"\n",
    "        Vectorizes all questions using the vectorize function.\n",
    "        Builds a list containing class number for each question.        \n",
    "        \"\"\"\n",
    "        texts = []\n",
    "        class_labels = []\n",
    "        \n",
    "        for i, t in enumerate(self.knowledge_base):\n",
    "            texts.append(t['question'])\n",
    "            texts += t['paraphrased_questions']\n",
    "\n",
    "            class_labels.append(i)\n",
    "            class_labels += [i]*len(t['paraphrased_questions'])\n",
    "        \n",
    "        \n",
    "        return self.vectorize(texts), class_labels\n",
    "    \n",
    "    def compute_class_scores(self, similarities):\n",
    "        \"\"\"\n",
    "        Accepts an array of similarities of shape (self.class_indexes, )\n",
    "        Computes scores for classes.\n",
    "        Returns a dictionary of size (n_classes) that looks like\n",
    "        {\n",
    "            0: 0.3,\n",
    "            1: 0.1,\n",
    "            2: 0.0,\n",
    "            class_n_id: class_n_score\n",
    "            ...\n",
    "        }\n",
    "        \"\"\"\n",
    "        \n",
    "        class_scores = dict(zip(range(len(self.answers)), [0]*len(self.answers)))\n",
    "        \n",
    "        for ci, sc in zip(self.class_indexes, similarities):\n",
    "            class_scores[ci] += sc\n",
    "        return class_scores\n",
    "        \n",
    "    def tokenize_and_lemmatize(self, text):\n",
    "        analysis = self.lemmatizer.analyze(text.strip())\n",
    "        tokens = []\n",
    "        for an in analysis:\n",
    "            if 'analysis' in an:\n",
    "                try:\n",
    "                    tokens.append(an['analysis'][0]['lex'])\n",
    "                except IndexError:\n",
    "                    tokens.append(an['text'])\n",
    "        return tokens\n",
    "    \n",
    "    def get_top(self, query, top_k=1):\n",
    "        if isinstance(query, str):\n",
    "            query = [query]\n",
    "            \n",
    "        vectorized_query = self.vectorize(query)\n",
    "        css = cosine_similarity(vectorized_query, self.vectorized_kbase)[0]\n",
    "        scores = self.compute_class_scores(css)\n",
    "        \n",
    "        sorted_scores = sorted(scores.items(), key= lambda x: x[1])[::-1][:top_k]\n",
    "        top_classes = np.array([c[0] for c in sorted_scores])\n",
    "        top_answers = list(self.answers[top_classes])\n",
    "        return top_answers[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill the cells with texts that your bot will react to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAQ = [{'question':'прогноз погоды', 'answer': get_weather, 'paraphrased_questions':['что там на улице']},\n",
    "       {'question':'your command here', 'answer': get_anekdot, 'paraphrased_questions':['your_paraphrases_here']},\n",
    "       {'question':'your command here', 'answer': get_rates, 'paraphrased_questions': ['your_paraphrases_here']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng = ENGINE_3(FAQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engine returns the most relevant callable function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng.get_top('дай прогноз')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrate the engine into your bot so that he obeys your commands!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import logging\n",
    "import telegram\n",
    "\n",
    "from telegram.ext import Updater, CommandHandler, MessageHandler, Filters\n",
    "\n",
    "from speech2text import speech2text\n",
    "from config import TOKEN, LOG_FILE, DL_DIR\n",
    "\n",
    "\n",
    "# Enable logging\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# Logging to file\n",
    "fh = logging.FileHandler(LOG_FILE)\n",
    "fh.setLevel(logging.DEBUG)\n",
    "fh.setFormatter(formatter)\n",
    "# Logging to console\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.DEBUG)\n",
    "ch.setFormatter(formatter)\n",
    "\n",
    "logger.addHandler(fh)\n",
    "logger.addHandler(ch)\n",
    "\n",
    "\n",
    "class Bot:\n",
    "    def __init__(self):\n",
    "\n",
    "        self.updater = Updater(TOKEN)\n",
    "        self.dsp = self.updater.dispatcher\n",
    "\n",
    "        # register handler functions which define how the bot reacts to events\n",
    "        self.dsp.add_handler(CommandHandler(\"start\", get_help))\n",
    "        self.dsp.add_handler(CommandHandler(\"help\", get_help))\n",
    "        self.dsp.add_handler(MessageHandler(Filters.text, echo))\n",
    "        self.dsp.add_handler(MessageHandler(Filters.voice, process_audio))\n",
    "        Filters.audio\n",
    "        self.dsp.add_error_handler(error)\n",
    "\n",
    "        logger.info('Im alive!')\n",
    "\n",
    "    def power_on(self):\n",
    "        # start the Bot\n",
    "        self.updater.start_polling()\n",
    "        self.updater.idle()\n",
    "\n",
    "def echo(bot, update):\n",
    "    logger.info('echo recieved message: {}'.format(update.message.text))\n",
    "    bot.sendMessage(update.message.chat_id, text=update.message.text)\n",
    "\n",
    "\n",
    "def error(bot, update, error):\n",
    "    # all uncaught telegram-related exceptions will be rerouted here\n",
    "    logger.error('Update \"%s\" caused error \"%s\"' % (update, error))\n",
    "\n",
    "\n",
    "def get_help(bot, update):\n",
    "    logger.info('get_help recieved message: {}'.format(update.message.text))\n",
    "    help_msg = ('Greetings, {} {}! Name is {}, at your service.\\n'\n",
    "                'My purpose is to demonstrate how ').format(\n",
    "        update.message.from_user.first_name, update.message.from_user.last_name, bot.name)\n",
    "    bot.sendMessage(update.message.chat_id, text=help_msg)\n",
    "    \n",
    "    \n",
    "def process_audio(bot, update):\n",
    "    logger.info('process_audio recieved: {}'.format(''))\n",
    "    loop = asyncio.new_event_loop()\n",
    "    asyncio.set_event_loop(loop)\n",
    "    try:\n",
    "\n",
    "        voice_file_id = update.message.voice.file_id\n",
    "        voice_file = bot.get_file(voice_file_id)\n",
    "        ogg_fname = \"{}/{}\".format(DL_DIR, \"voice.ogg\")\n",
    "        voice_file.download(ogg_fname)\n",
    "        logger.info('downloaded')\n",
    "        transcript = speech2text(ogg_fname)\n",
    "        logger.info('transcription result: {}'.format(transcript))\n",
    "\n",
    "        # your code goes here\n",
    "        func_output = ''\n",
    "        \n",
    "        bot.sendMessage(update.message.chat_id, text=func_output)\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(e)\n",
    "\n",
    "my_bot = Bot()\n",
    "my_bot.power_on()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
