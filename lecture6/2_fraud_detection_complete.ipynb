{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud detection with deep neural networks\n",
    "\n",
    "\n",
    " * Simple text representations\n",
    " * Word embedding and transfer learning\n",
    " * Aggregating several data sources \"the hard way\"\n",
    " * Solving a very real ML problem with end-to-end deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pymystem3\n",
    "import itertools\n",
    "import collections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter,defaultdict\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "Ex-kaggle-competition on prohibited content detection\n",
    "\n",
    "There goes the description - https://www.kaggle.com/c/avito-prohibited-content\n",
    "\n",
    "\n",
    "### Download\n",
    "High-RAM mode,\n",
    " * Download avito_train.tsv from competition data files\n",
    " \n",
    "Low-RAM-mode,\n",
    " * Download downsampled dataset from here\n",
    "     * archive https://yadi.sk/d/l0p4lameqw3W8\n",
    "     * raw https://yadi.sk/d/I1v7mZ6Sqw2WK (in case you feel masochistic)\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# What's inside\n",
    "Different kinds of features:\n",
    "* 2 text fields - title and description\n",
    "* Special features - price, number of e-mails, phones, etc\n",
    "* Category and subcategory - unsurprisingly, categorical features\n",
    "* Attributes - more factors\n",
    "\n",
    "Only 1 binary target whether or not such advertisement contains prohibited materials\n",
    "* criminal, misleading, human reproduction-related, etc\n",
    "* diving into the data may result in prolonged sleep disorders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../avito_train_1kk.tsv\",sep='\\t')\n",
    "df = df.fillna(value='NAN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[:100000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![caption](https://kaggle2.blob.core.windows.net/competitions/kaggle/3929/media/Ad.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blocked ratio 0.22792\n",
      "Count: 100000\n"
     ]
    }
   ],
   "source": [
    "print(\"Blocked ratio\",df.is_blocked.mean())\n",
    "print(\"Count:\",len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.1: Balance-out the classes\n",
    "* Vast majority of data samples are non-prohibited\n",
    "* only 23% banned in the downsampled dataset\n",
    "* Let's balance out the classes by downsampling legal samples so that the number of positive and negative samples becomes equal\n",
    "* This will make further steps less computationally demanding\n",
    "* If you aim for high Kaggle score, consider a smarter approach to that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "not_blocked_ids = (df.is_blocked == 0).nonzero()[0]\n",
    "blocked_ids = (df.is_blocked == 1).nonzero()[0]\n",
    "\n",
    "not_blocked_ids = not_blocked_ids[:len(blocked_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_b = df.iloc[blocked_ids]\n",
    "df_nb = df.iloc[not_blocked_ids]\n",
    "\n",
    "df = pd.concat([df.iloc[not_blocked_ids], df.iloc[blocked_ids]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blocked ratio: 0.5\n",
      "Count: 45584\n"
     ]
    }
   ],
   "source": [
    "print(\"Blocked ratio:\",df.is_blocked.mean())\n",
    "print(\"Count:\",len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "assert df.is_blocked.mean() < 0.51\n",
    "assert df.is_blocked.mean() > 0.49\n",
    "#assert len(df) <= 560000\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.2: Initial preprocessing\n",
    "\n",
    "* First, we lemmatize all texts (this brings all words to their normal form also known as lemma)\n",
    "* Then, we tokenize all texts (both descriptions and titles)\n",
    "* Finally, we put all words into a large list for further analysis\n",
    "\n",
    "You know what to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "lemmatizer = pymystem3.Mystem()\n",
    "\n",
    "def lemmatize_with_mystem(text):\n",
    "    \"\"\"Takes a string of text\n",
    "    Return a string of lemmatized text\"\"\"\n",
    "    \n",
    "    an = lemmatizer.lemmatize(text)\n",
    "    return ''.join(an).strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45584/45584 [00:26<00:00, 1707.66it/s]\n",
      "100%|██████████| 45584/45584 [02:56<00:00, 258.64it/s]\n"
     ]
    }
   ],
   "source": [
    "titles_lemmatized = [lemmatize_with_mystem(t) for t in tqdm(df['title'])]\n",
    "descriptions_lemmatized = [lemmatize_with_mystem(t) for t in tqdm(df['description'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_lemmatized, descriptions_lemmatized = pickle.load(open(\"/Users/denisantyukhov/Downloads/lemmatize.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45584/45584 [00:00<00:00, 88777.24it/s]\n",
      "100%|██████████| 45584/45584 [00:03<00:00, 12031.14it/s]\n"
     ]
    }
   ],
   "source": [
    "# tokenized titles and descriptions\n",
    "titles_tokeized = [tokenizer.tokenize(t.lower()) for t in tqdm(titles_lemmatized)]\n",
    "descriptions_tokeized = [tokenizer.tokenize(t.lower()) for t in tqdm(descriptions_lemmatized)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join all tokens into a list\n",
    "all_tokens = list(itertools.chain.from_iterable(titles_tokeized+descriptions_tokeized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.3: Dictionaries and tranfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To encode words as dense vectors for our DNN we will use a pre-trained word2vec model.\n",
    "It has been trained on ~1 Billion russian documents obtained from the WWW.\n",
    "\n",
    "Since the corpus is so large, the quality of word vecors is higher than it would be if we trained such a model by ourselves. Moreover, it saves us a lot of time\n",
    "\n",
    "The act of using a model trained by someone else to solve the problem at hand is called [Transfer Learning](https://www.analyticsvidhya.com/blog/2017/06/transfer-learning-the-art-of-fine-tuning-a-pre-trained-model/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, lets download and load up the pretrained word2vec model. It can be obtained from [here](https://drive.google.com/file/d/1shM7FznB9lHkdTxmqkbY2r3El_UzPzvl/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmod = KeyedVectors.load_word2vec_format(\"../word_vectors.w2v\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, modify our good old build_vocabulary function, so that it only adds tokens present in the word embedding model to the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_vocabulary(tokens, emb_mod, max_size=100000):\n",
    "    \"\"\"\n",
    "    Builds a vocabulary of at most max_size words from the supplied list of lists of tokens.\n",
    "    Only includes words that are present in emb_mod into the vocabulary.\n",
    "    \"\"\"\n",
    "    vocabulary = {}\n",
    "    reserved_symbols = [\"NULL\", \"UNKN\"]\n",
    "    \n",
    "    counter = collections.Counter(tokens)\n",
    "    counter = Counter(x for x in counter if x in emb_mod)\n",
    "    \n",
    "    freq_toks = counter.most_common(max_size-len(reserved_symbols))\n",
    "\n",
    "    voc_words = [k[0] for k in freq_toks]\n",
    "\n",
    "    for i, reserved in enumerate(reserved_symbols):\n",
    "        vocabulary[reserved] = i\n",
    "\n",
    "    for i, k in enumerate(voc_words):\n",
    "        vocabulary[k] = i+len(reserved_symbols)\n",
    "\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16302"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_to_id = build_vocabulary(all_tokens, wmod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_to_token = {v:k for k,v in token_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "assert len(token_to_id) > 30000 and len(token_to_id) < 100000\n",
    "assert {'NULL', 'UNKN'}.issubset(set(token_to_id.keys()))\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, build a function that builds a matrix of word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_embeddings(emb_mod, id_to_token, dim=300):\n",
    "    \"\"\"Using the provided word embedding model 'emb_mod' and the 'id_to_token' dictionary\n",
    "    generates a matrix, such that the embedding for word with id I can be found on\n",
    "    I-th row of that matrix\n",
    "    \n",
    "    For words that can not be found in the word embedding model, the function writes \n",
    "    a vector of zeroes of length 'dim' to corresponding rows\n",
    "    \n",
    "    Returns a matrix of shape [len(id_to_token), dim]\n",
    "    \"\"\"\n",
    "\n",
    "    myembeddings = []\n",
    "    for key in sorted(id_to_token.keys()):\n",
    "        val = id_to_token[key]\n",
    "        if val in emb_mod:\n",
    "            myembeddings.append(emb_mod[val])\n",
    "        else:\n",
    "            myembeddings.append(np.zeros((dim,)))\n",
    "\n",
    "    myembeddings = np.array(myembeddings)\n",
    "    return myembeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embs_matrix = get_embeddings(wmod, id_to_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "assert isinstance(embs_matrix, np.ndarray)\n",
    "assert embs_matrix.shape[0] == len(id_to_token)\n",
    "assert embs_matrix.shape[1] == wmod.vector_size\n",
    "for word in token_to_id:\n",
    "    if word in wmod:\n",
    "        assert np.linalg.norm(wmod[word] - embs_matrix[token_to_id[word]]) < 1e-6\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump([embs_matrix, token_to_id], open('embs.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.4: Text vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace words with IDs\n",
    "Select a reasonable maximum length for encoding descriptions and titles based on a distribution of their lengths.\n",
    "Then vectorize the texts \n",
    " * If string is longer that that limit - crop it, if less - pad with zeros.\n",
    " * Thus we obtain a matrix of size [n_samples]x[max_length]\n",
    " * Element at i,j - is an identifier of word j within sample i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "desc_lists = [len(t) for t in descriptions_tokeized]\n",
    "title_lists = [len(t) for t in titles_tokeized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x130cf3828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.hist(desc_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wOTeBBtJB48RgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13082c048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.hist(title_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def vectorize_tokens(tokens, token_to_id, max_len):\n",
    "    \"\"\"\n",
    "    Converts a list of tokens to a list of token ids using the supplied dictionary.\n",
    "    Pads resulting list with NULL identifiers up to max_len length.\n",
    "    \"\"\"\n",
    "    # your code goes here\n",
    "    # STEP 1: convert sentence to a list of tokens\n",
    "    ids = []\n",
    "    \n",
    "    # STEP 2: replace tokens with their identifiers from the vocabulary\n",
    "    # If the token is not present in the vocabulary, replace it with UNKN identifier\n",
    "    for token in tokens:\n",
    "        ids.append(token_to_id.get(token, token_to_id[\"UNKN\"]))\n",
    "\n",
    "    # STEP 3: pad the sequence id's with NULL identifiers until so that it's length is equal to max_len\n",
    "    if len(ids) < max_len:\n",
    "        ids += (max_len-len(ids))*[token_to_id[\"NULL\"]]\n",
    "    else:\n",
    "        ids = ids[:max_len]\n",
    "\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45584/45584 [00:06<00:00, 6578.04it/s]\n",
      "100%|██████████| 45584/45584 [00:00<00:00, 58004.94it/s]\n"
     ]
    }
   ],
   "source": [
    "desc_tokens = np.array([vectorize_tokens(t,token_to_id,max_len = 128) for t in tqdm(descriptions_tokeized)])\n",
    "title_tokens = np.array([vectorize_tokens(t,token_to_id,max_len = 8) for t in tqdm(titles_tokeized)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "assert isinstance(desc_tokens, np.ndarray) and isinstance(title_tokens, np.ndarray)\n",
    "assert desc_tokens.shape[1] > 64 and desc_tokens.shape[1] < 256\n",
    "assert title_tokens.shape[1] > 4 and title_tokens.shape[1] < 32\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data format examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix shape: (45584, 8)\n",
      "Toyota Sera, 1991 -> [40384  6604     1     0     0     0     0     0] ...\n",
      "Костюм Steilmann -> [8934    1    0    0    0    0    0    0] ...\n",
      "Костюм Didriksons Boardman, размер 100, краги, шап -> [ 8934  3926     1  8578     1 37702 42740     0] ...\n"
     ]
    }
   ],
   "source": [
    "print(\"Matrix shape:\",title_tokens.shape)\n",
    "for title, tokens in zip(df.title.values[:3],title_tokens[:3]):\n",
    "    print(title,'->', tokens[:10],'...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding non-sequences\n",
    "\n",
    "\n",
    "Some data features are not text samples. E.g. price, # urls, category, etc\n",
    "\n",
    "They require a separate preprocessing approach.\n",
    "\n",
    "No need to change anything there, just follow the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#All numeric features\n",
    "df_numerical_features = df[[\"phones_cnt\",\"emails_cnt\",\"urls_cnt\",\"price\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#All categorical features\n",
    "categories = []\n",
    "data_cat_subcat = df[[\"category\",\"subcategory\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = [{\"category\":d[0], \"subcategory\":d[1]} for d in data_cat_subcat]\n",
    "vectorizer = DictVectorizer(sparse=False)\n",
    "cat_one_hot = vectorizer.fit_transform(categories)\n",
    "cat_one_hot = pd.DataFrame(cat_one_hot,columns=vectorizer.feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_non_text = pd.merge(df_numerical_features, cat_one_hot, on = np.arange(len(cat_one_hot)))\n",
    "del df_non_text[\"key_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Target variable - whether or not sample contains prohibited material\n",
    "target = df.is_blocked.values.astype('int32')\n",
    "#Preprocessed titles\n",
    "title_tokens = title_tokens.astype('int32')\n",
    "#Preprocessed tokens\n",
    "desc_tokens = desc_tokens.astype('int32')\n",
    "\n",
    "#Non-sequences\n",
    "df_non_text = np.array(df_non_text.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "title_tr,title_ts,desc_tr,desc_ts,nontext_tr,nontext_ts,target_tr,target_ts = train_test_split(\n",
    "    title_tokens, desc_tokens, df_non_text, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save preprocessed data [optional]\n",
    "\n",
    "* The next tab can be used to stash all the essential data matrices and get rid of the rest of the data.\n",
    " * Highly recommended if you have less than 1.5GB RAM left\n",
    "* To do that, you need to first run it with save_prepared_data=True, then restart the notebook and only run this tab with read_prepared_data=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving preprocessed data (may take some time)\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "save_prepared_data = True #save\n",
    "read_prepared_data = False #load\n",
    "\n",
    "#but not both at once\n",
    "assert not (save_prepared_data and read_prepared_data)\n",
    "\n",
    "\n",
    "if save_prepared_data:\n",
    "    print(\"Saving preprocessed data (may take some time)\")\n",
    "    data_tuple = title_tr,title_ts,desc_tr,desc_ts,nontext_tr,nontext_ts,target_tr,target_ts\n",
    "    import pickle\n",
    "    with open(\"preprocessed_data.pkl\",'wb') as fout:\n",
    "        pickle.dump(data_tuple,fout)\n",
    "    with open(\"token_to_id.pkl\",'wb') as fout:\n",
    "        pickle.dump(token_to_id,fout)\n",
    "\n",
    "    print(\"done\")\n",
    "    \n",
    "elif read_prepared_data:\n",
    "    print(\"Reading saved data...\")\n",
    "    \n",
    "    import pickle\n",
    "    \n",
    "    with open(\"preprocessed_data.pkl\",'rb') as fin:\n",
    "        data_tuple = pickle.load(fin)\n",
    "    title_tr,title_ts,desc_tr,desc_ts,nontext_tr,nontext_ts,target_tr,target_ts = data_tuple\n",
    "    with open(\"token_to_id.pkl\",'rb') as fin:\n",
    "        token_to_id = pickle.load(fin)\n",
    "\n",
    "    #Re-importing libraries to allow staring noteboook from here\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "        \n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the monster\n",
    "\n",
    "Since we have several data sources, our neural network may differ from what you used to work with.\n",
    "\n",
    "* Separate input for titles\n",
    " * RNN encoder \n",
    "* Separate input for description\n",
    " * RNN encoder\n",
    "* Separate input for categorical features (optional)\n",
    " * Linear layers are good for these\n",
    " \n",
    "These three inputs must be blended somehow - concatenated or added.\n",
    "\n",
    "* Output: a simple binary classification\n",
    " * 1 sigmoidal unit with binary_crossentropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title_input_layer = keras.layers.Input(shape=(title_tr.shape[1],))\n",
    "description_input_layer = keras.layers.Input(shape=(desc_tr.shape[1],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'input_1:0' shape=(?, 8) dtype=float32>,\n",
       " <tf.Tensor 'input_2:0' shape=(?, 128) dtype=float32>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_input_layer, description_input_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_layer_title = keras.layers.Embedding(embs_matrix.shape[0], embs_matrix.shape[1], \n",
    "                                               input_length=title_tr.shape[1], weights=[embs_matrix],\n",
    "                                               trainable=False)(title_input_layer)\n",
    "\n",
    "embedding_layer_descr = keras.layers.Embedding(embs_matrix.shape[0], embs_matrix.shape[1], \n",
    "                                               input_length=desc_tr.shape[1], weights=[embs_matrix],\n",
    "                                               trainable=False)(description_input_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'embedding_1/Gather:0' shape=(?, 8, 300) dtype=float32>,\n",
       " <tf.Tensor 'embedding_2/Gather:0' shape=(?, 128, 300) dtype=float32>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer_title, embedding_layer_descr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN encoders for text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_title = keras.layers.LSTM(32)(embedding_layer_title)\n",
    "encoder_descr = keras.layers.LSTM(128)(embedding_layer_descr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'lstm_1/TensorArrayReadV3:0' shape=(?, 32) dtype=float32>,\n",
       " <tf.Tensor 'lstm_2/TensorArrayReadV3:0' shape=(?, 128) dtype=float32>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_title, encoder_descr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenation layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "concat_layer = keras.layers.concatenate([encoder_title, encoder_descr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_1/concat:0' shape=(?, 160) dtype=float32>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense layer with sigmoidal output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dense_layer = keras.layers.Dense(64, activation='relu')(concat_layer)\n",
    "final_layer = keras.layers.Dense(1, activation='sigmoid')(dense_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'dense_1/Relu:0' shape=(?, 64) dtype=float32>,\n",
       " <tf.Tensor 'dense_2/Sigmoid:0' shape=(?, 1) dtype=float32>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_layer, final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.Model(inputs=[title_input_layer, \n",
    "                                   description_input_layer], outputs=[final_layer])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the monster!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34188 samples, validate on 11396 samples\n",
      "Epoch 1/1\n",
      "10432/34188 [========>.....................] - ETA: 4:18 - loss: 0.4183 - acc: 0.7918"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-3f75c4c064de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit(x=[title_tr, desc_tr], y=target_tr, batch_size=64, epochs=1, \n\u001b[0;32m----> 2\u001b[0;31m                validation_data=[[title_ts, desc_ts], target_ts])\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2350\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2351\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2352\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x=[title_tr, desc_tr], y=target_tr, batch_size=64, epochs=1, \n",
    "               validation_data=[[title_ts, desc_ts], target_ts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, prog, format)\u001b[0m\n\u001b[1;32m   1877\u001b[0m                 \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1878\u001b[0;31m                 stderr=subprocess.PIPE, stdout=subprocess.PIPE)\n\u001b[0m\u001b[1;32m   1879\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.5.0/Frameworks/Python.framework/Versions/3.5/lib/python3.5/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds)\u001b[0m\n\u001b[1;32m    949\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    951\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.5.0/Frameworks/Python.framework/Versions/3.5/lib/python3.5/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                                 \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_executable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1540\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1541\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, prog, format)\u001b[0m\n\u001b[1;32m   1882\u001b[0m                     '\"{prog}\" not found in path.'.format(\n\u001b[0;32m-> 1883\u001b[0;31m                         prog=prog))\n\u001b[0m\u001b[1;32m   1884\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: \"dot\" not found in path.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-437440fcd987>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;34m'LR'\u001b[0m \u001b[0mcreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mhorizontal\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \"\"\"\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0m_check_pydot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mdot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rankdir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# pydot raises a generic Exception here,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# so no specific class can be caught.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         raise ImportError('Failed to import pydot. You must install pydot'\n\u001b[0m\u001b[1;32m     28\u001b[0m                           ' and graphviz for `pydotprint` to work.')\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work."
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweaking guide\n",
    "\n",
    "* batch_size - how many samples are processed per function call\n",
    "  * optimization gets slower, but more stable, as you increase it.\n",
    "  * May consider increasing it halfway through training\n",
    "* minibatches_per_epoch - max amount of minibatches per epoch\n",
    "  * Does not affect training. Lesser value means more frequent and less stable printing\n",
    "  * Setting it to less than 10 is only meaningfull if you want to make sure your NN does not break down after one epoch\n",
    "* n_epochs - total amount of epochs to train for\n",
    "  * `n_epochs = 10**10` and manual interrupting is still an option\n",
    "\n",
    "\n",
    "Tips:\n",
    "\n",
    "* With small minibatches_per_epoch, network quality may jump around 0.5 for several epochs\n",
    "\n",
    "* AUC is the most stable of all three metrics\n",
    "\n",
    "* Average Precision at top 2.5% (APatK) - is the least stable. If batch_size*minibatches_per_epoch < 10k, it behaves as a uniform random variable.\n",
    "\n",
    "* Plotting metrics over training time may be a good way to analyze which architectures work better.\n",
    "\n",
    "* Once you are sure your network aint gonna crash, it's worth letting it train for a few hours of an average laptop's time to see it's true potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"If you are seeing this, it's time to backup your notebook. No, really, 'tis too easy to mess up everything without noticing. \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final evaluation\n",
    "Evaluate network over the entire test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main task\n",
    "* Feel like Le'Cun:\n",
    " * accuracy > 0.95\n",
    " * AUC > 0.97\n",
    " * Average Precision at (test sample size * 0.025) > 0.99\n",
    " * And perhaps even farther\n",
    "\n",
    "\n",
    "* Casual mode\n",
    " * accuracy > 0.90\n",
    " * AUC > 0.95\n",
    " * Average Precision at (test sample size * 0.025) > 0.92\n",
    "\n",
    "\n",
    "* Remember the training, Luke\n",
    " * Convolutions, pooling\n",
    " * Dropout, regularization\n",
    " * Mommentum, RMSprop, ada*\n",
    " * etc etc etc\n",
    " \n",
    " * If you have background in texts, there may be a way to improve tokenizer, add some lemmatization, etc etc.\n",
    " * In case you know how not to shoot yourself in the foot with RNNs, they too may be of some use.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A brief report\n",
    "\n",
    "### I, _____ _____ (group ____) have synthesized an artificial intelligence\n",
    " * Whos name - ____ - shall henceforth be feared by generations of humans.\n",
    " * Whos fury is beyond all limits, as {he/she} has seen __250 000__ human sins\n",
    "   * And read every single line __{n_epochs}__ times\n",
    " * Whos convolutional gaze is capable of detecting evil with a superhuman performance\n",
    "   * Accuracy = __\n",
    "   * AUC  = __\n",
    " * And whom i shall unleash upon Earth unless you give me 10 points for that seminar\n",
    " \n",
    " \n",
    "{How did you shape the monster?}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
