{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval-based systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieval-based bots answer user queries by retrieving the most relevant answer from a pre-defined knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import scipy\n",
    "import pymystem3\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import KeyedVectors\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knowledge_base = json.load(open(\"./faq_train.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's have a look at our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knowledge_base[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions to evaluate your IR engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_score_for_engine(engine, val_json_path):\n",
    "    data = []\n",
    "    for q in json.load(open(val_json_path)):\n",
    "        queries = q['paraphrased_questions']\n",
    "        answer = q['answer']\n",
    "        results = [engine.get_top(query, top_k=3) for query in queries]\n",
    "        for r in results:\n",
    "            data.append([answer] + r)\n",
    "            \n",
    "    ra1 = calc_recall(data, 1)\n",
    "    ra3 = calc_recall(data, 3)\n",
    "    print(\"recall @1: {}\\nrecall @3: {}\".format(ra1, ra3))\n",
    "    return ra1, ra3\n",
    "            \n",
    "def calc_recall(data, k, bootstrap=0, subsample_rate=None):\n",
    "    \"\"\"\n",
    "    :param data: 2d matrix\n",
    "    data[i, 0] - true answer, data[i, 1:] - predicted answers, sorted by decreasing score.\n",
    "    \"\"\"\n",
    "    count = np.zeros(1 + bootstrap)\n",
    "    count_hit = np.zeros(1 + bootstrap)\n",
    "    for fields in data:\n",
    "        query = fields[0]\n",
    "\n",
    "        if subsample_rate is None:\n",
    "            increment = np.random.poisson(lam=1, size=bootstrap)\n",
    "        else:\n",
    "            increment = np.random.binomial(1, subsample_rate, bootstrap)\n",
    "        increment = np.hstack([[1], increment])\n",
    "\n",
    "        if query in fields[1:k+1]:\n",
    "            count_hit += increment\n",
    "        count += increment\n",
    "\n",
    "    recall = count_hit / count\n",
    "\n",
    "    return recall[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we build a basic IR system using a TF-IDF representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ENGINE_1(object):\n",
    "    def __init__(self, kbase_path):\n",
    "        self.knowledge_base = json.load(open(kbase_path))\n",
    "        self.lemmatizer = pymystem3.Mystem()\n",
    "        \n",
    "        # contains correct output for each class\n",
    "        self.answers = np.array([t['answer'] for t in self.knowledge_base])\n",
    "        \n",
    "\n",
    "        self.vectorizer = self.prepare_vectorizer()\n",
    "        self.vectorized_kbase, self.class_indexes = self.vectorize_knowledge_base()\n",
    "        \n",
    "    \n",
    "    def prepare_vectorizer(self):\n",
    "        \"\"\"\n",
    "        Fits TF-IDF vectorizer using all available text from self.knowledge_base\n",
    "        \n",
    "        Returns TF-IDF vectorizer object\n",
    "        \"\"\"\n",
    "        # your code goes here\n",
    "        vectorizer = None\n",
    "        all_texts = []\n",
    "\n",
    "        return vectorizer\n",
    "    \n",
    "    def vectorize(self, data):\n",
    "        \"\"\"\n",
    "        Turns a list of N strings into their vector representation using self.vectorizer.\n",
    "        \n",
    "        Returns a a matrix of shape [N, n_features]\n",
    "        \"\"\"\n",
    "        # your code goes here\n",
    "        vectorized = None\n",
    "        return \n",
    "        \n",
    "    def vectorize_knowledge_base(self):\n",
    "        \"\"\"\n",
    "        Vectorizes all questions using the vectorize function.\n",
    "        Builds a list containing class id (it's index in self.knowledge_base) for each question.\n",
    "        \n",
    "        Returns vectorized questions and a list of class ids\n",
    "        \"\"\"\n",
    "        questions = [t['question'] for t in self.knowledge_base]\n",
    "        return self.vectorize(questions), list(range(len(self.knowledge_base)))\n",
    "    \n",
    "    def compute_class_scores(self, similarities):\n",
    "        \"\"\"\n",
    "        Accepts an array of similarities of shape (self.class_indexes, )\n",
    "        Computes scores for classes.\n",
    "        \n",
    "        Returns a dictionary of size (n_classes) that looks like\n",
    "        {\n",
    "            0: 0.3,\n",
    "            1: 0.1,\n",
    "            2: 0.0,\n",
    "            class_n_id: class_n_score\n",
    "            ...\n",
    "        }\n",
    "        \"\"\"\n",
    "        # your code goes here\n",
    "\n",
    "        return class_scores\n",
    "        \n",
    "    def tokenize_and_lemmatize(self, text):\n",
    "        analysis = self.lemmatizer.analyze(text.strip())\n",
    "        tokens = []\n",
    "        for an in analysis:\n",
    "            if 'analysis' in an:\n",
    "                try:\n",
    "                    tokens.append(an['analysis'][0]['lex'])\n",
    "                except IndexError:\n",
    "                    tokens.append(an['text'])\n",
    "        return tokens\n",
    "    \n",
    "    def get_top(self, query, top_k=3):\n",
    "        if isinstance(query, str):\n",
    "            query = [query]\n",
    "            \n",
    "        vectorized_query = self.vectorize(query)\n",
    "        css = cosine_similarity(vectorized_query, self.vectorized_kbase)[0]\n",
    "        scores = self.compute_class_scores(css)\n",
    "        \n",
    "        sorted_scores = sorted(scores.items(), key= lambda x: x[1])[::-1][:top_k]\n",
    "        top_classes = np.array([c[0] for c in sorted_scores])\n",
    "        top_answers = list(self.answers[top_classes])\n",
    "        return top_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engine1 = ENGINE_1(\"./faq_train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1 = engine1.prepare_vectorizer()\n",
    "assert isinstance(t1, TfidfVectorizer)\n",
    "assert len(t1.get_feature_names()) > 1500\n",
    "print(\"prepare vectorizer OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t2 = engine1.vectorize(['Как получить ЗП-карту?',\n",
    "   'А можно зарплатную карту вне очереди получить - очень надо?',\n",
    "   'Как быть с зарплатой?'])\n",
    "\n",
    "assert isinstance(t2, scipy.sparse.csr_matrix)\n",
    "assert t2.shape[0] == 3 and t2.shape[1] == len(engine1.vectorizer.get_feature_names())\n",
    "print(\"vectorize OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t3 = engine1.compute_class_scores(np.arange(0,1,0.034))\n",
    "assert isinstance(t3, dict)\n",
    "assert list(t3.items()) == list(zip(range(30), np.arange(0,1,0.034)))\n",
    "print(\"compute_class_scores OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r1, r3 = calc_score_for_engine(engine1, \"./faq_val.json\")\n",
    "assert r1 >0.5\n",
    "assert r3 >0.75\n",
    "print(\"scores OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we improve our IR system using word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v = KeyedVectors.load_word2vec_format(\"word_vectors.w2v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ENGINE_2(object):\n",
    "    def __init__(self, kbase_path, w2v_model):\n",
    "        self.knowledge_base = json.load(open(kbase_path))\n",
    "        self.lemmatizer = pymystem3.Mystem()\n",
    "        self.w2v_model = w2v_model\n",
    "        \n",
    "        # contains correct output for each class\n",
    "        self.answers = np.array([t['answer'] for t in self.knowledge_base])\n",
    "        \n",
    "\n",
    "        self.vectorized_kbase, self.class_indexes = self.vectorize_knowledge_base()\n",
    "    \n",
    "    def vectorize(self, data):\n",
    "        \"\"\"\n",
    "        Turns a list of N strings into their vector representation using self.w2v_model.\n",
    "        In the simplest case, averages the word vectors of all words in a sentence.\n",
    "        \n",
    "        Returns a a matrix of shape [N, 300] (300 = word vector dimensionality)\n",
    "        \"\"\"\n",
    "        vectorized = []\n",
    "        # your code goes here\n",
    "        return np.array(vectorized)\n",
    "        \n",
    "    def vectorize_knowledge_base(self):\n",
    "        \"\"\"\n",
    "        Vectorizes all questions using the vectorize function.\n",
    "        Builds a list containing class id (it's index in self.knowledge_base) for each question.\n",
    "        \n",
    "        Returns vectorized questions and a list of class ids\n",
    "        \"\"\"\n",
    "        questions = [t['question'] for t in self.knowledge_base]\n",
    "        return self.vectorize(questions), list(range(len(self.knowledge_base)))\n",
    "    \n",
    "    def compute_class_scores(self, similarities):\n",
    "        \"\"\"\n",
    "        Accepts an array of similarities of shape (self.class_indexes, )\n",
    "        Computes scores for classes.\n",
    "        Returns a dictionary of size (n_classes) that looks like\n",
    "        {\n",
    "            0: 0.3,\n",
    "            1: 0.1,\n",
    "            2: 0.0,\n",
    "            class_n_id: class_n_score\n",
    "            ...\n",
    "        }\n",
    "        \"\"\"\n",
    "        \n",
    "        # your code goes here\n",
    "        return class_scores\n",
    "        \n",
    "    def tokenize_and_lemmatize(self, text):\n",
    "        analysis = self.lemmatizer.analyze(text.strip())\n",
    "        tokens = []\n",
    "        for an in analysis:\n",
    "            if 'analysis' in an:\n",
    "                try:\n",
    "                    tokens.append(an['analysis'][0]['lex'])\n",
    "                except IndexError:\n",
    "                    tokens.append(an['text'])\n",
    "        return tokens\n",
    "    \n",
    "    def get_top(self, query, top_k=3):\n",
    "        if isinstance(query, str):\n",
    "            query = [query]\n",
    "            \n",
    "        vectorized_query = self.vectorize(query)\n",
    "        css = cosine_similarity(vectorized_query, self.vectorized_kbase)[0]\n",
    "        scores = self.compute_class_scores(css)\n",
    "        \n",
    "        sorted_scores = sorted(scores.items(), key= lambda x: x[1])[::-1][:top_k]\n",
    "        top_classes = np.array([c[0] for c in sorted_scores])\n",
    "        top_answers = list(self.answers[top_classes])\n",
    "        return top_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engine2 = ENGINE_2(\"./faq_train.json\", w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1 = engine2.vectorize(['Как получить ЗП-карту?',\n",
    "   'А можно зарплатную карту вне очереди получить - очень надо?',\n",
    "   'Как быть с зарплатой?'])\n",
    "\n",
    "assert isinstance(t1, np.ndarray)\n",
    "assert t1.shape[0] == 3 and t1.shape[1] == 300\n",
    "print(\"vectorize OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r1, r3 = calc_score_for_engine(engine2, \"./faq_val.json\")\n",
    "assert r1 >0.65\n",
    "assert r3 >0.8\n",
    "print(\"scores OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we use available paraphrases to further improve the quiality of our IR system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ENGINE_3(object):\n",
    "    def __init__(self, kbase_path, w2v_model):\n",
    "        self.knowledge_base = json.load(open(kbase_path))\n",
    "        self.lemmatizer = pymystem3.Mystem()\n",
    "        self.w2v_model = w2v_model\n",
    "        \n",
    "        # contains correct output for each class\n",
    "        self.answers = np.array([t['answer'] for t in self.knowledge_base])\n",
    "        \n",
    "        self.vectorized_kbase, self.class_indexes = self.vectorize_knowledge_base()\n",
    "    \n",
    "    def vectorize(self, data):\n",
    "        \"\"\"\n",
    "        Turns a list of N strings into their vector representation using self.w2v_model.\n",
    "        In the simplest case, averages the word vectors of all words in a sentence.\n",
    "        Returns a a matrix of shape [N, 300]\n",
    "        \"\"\"\n",
    "        vectorized = []\n",
    "        \n",
    "        # your code goes here\n",
    "        \n",
    "        return np.array(vectorized)\n",
    "        \n",
    "    def vectorize_knowledge_base(self):\n",
    "        \"\"\"\n",
    "        Vectorizes all questions AND paraphrased questions using the vectorize function.\n",
    "        Builds a list containing class id (it's index in self.knowledge_base) for each vectorized question.\n",
    "        \n",
    "        Example: you vectorized 1 question and 5 paraphrases for that question\n",
    "        Then you should append the ID of the question to class_labels list 5+1=6 times.\n",
    "        \"\"\"\n",
    "        vectors = []\n",
    "        class_labels = []\n",
    "        \n",
    "        # your code goes here\n",
    "        \n",
    "        return vectors, class_labels\n",
    "    \n",
    "    def compute_class_scores(self, similarities):\n",
    "        \"\"\"\n",
    "        Accepts an array of similarities of shape (self.class_indexes, )\n",
    "        Computes scores for classes.\n",
    "        Returns a dictionary of size (n_classes) that looks like\n",
    "        {\n",
    "            0: 0.3,\n",
    "            1: 0.1,\n",
    "            2: 0.0,\n",
    "            class_n_id: class_n_score\n",
    "            ...\n",
    "        }\n",
    "        \"\"\"\n",
    "        \n",
    "        class_scores = dict(zip(range(len(self.answers)), [0]*len(self.answers)))\n",
    "        \n",
    "        # your code goes here\n",
    "        return class_scores\n",
    "        \n",
    "    def tokenize_and_lemmatize(self, text):\n",
    "        analysis = self.lemmatizer.analyze(text.strip())\n",
    "        tokens = []\n",
    "        for an in analysis:\n",
    "            if 'analysis' in an:\n",
    "                try:\n",
    "                    tokens.append(an['analysis'][0]['lex'])\n",
    "                except IndexError:\n",
    "                    tokens.append(an['text'])\n",
    "        return tokens\n",
    "    \n",
    "    def get_top(self, query, top_k=3):\n",
    "        if isinstance(query, str):\n",
    "            query = [query]\n",
    "            \n",
    "        vectorized_query = self.vectorize(query)\n",
    "        css = cosine_similarity(vectorized_query, self.vectorized_kbase)[0]\n",
    "        scores = self.compute_class_scores(css)\n",
    "        \n",
    "        sorted_scores = sorted(scores.items(), key= lambda x: x[1])[::-1][:top_k]\n",
    "        top_classes = np.array([c[0] for c in sorted_scores])\n",
    "        top_answers = list(self.answers[top_classes])\n",
    "        return top_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engine3 = ENGINE_3(\"./faq_train.json\", w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1 = engine3.vectorize_knowledge_base()\n",
    "\n",
    "assert isinstance(t1[0], np.ndarray)\n",
    "assert t1[0].shape[0] == len([t['answer'] for t in engine3.knowledge_base]) +len(list(chain.from_iterable(\n",
    "    [t['paraphrased_questions'] for t in engine3.knowledge_base])))\n",
    "\n",
    "print(\"vectorize knowledge base OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r1, r3 = calc_score_for_engine(engine3, \"./faq_val.json\")\n",
    "assert r1 >0.70\n",
    "assert r3 >0.85\n",
    "print(\"scores OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we use all our knowledge to push the performance of our IR system to the limit.\n",
    "\n",
    "Some suggestions:\n",
    "* Stopwords removal\n",
    "* Word-vector re-weighting (e.g. by idf score)\n",
    "* Combining both TF-IDF and word2vec representation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ENGINE_4(object):\n",
    "    def __init__(self, kbase_path, w2v_model):\n",
    "        self.knowledge_base = json.load(open(kbase_path))\n",
    "        self.lemmatizer = pymystem3.Mystem()\n",
    "        self.w2v_model = w2v_model\n",
    "        \n",
    "        # contains correct output for each class\n",
    "        self.answers = np.array([t['answer'] for t in self.knowledge_base])\n",
    "        \n",
    "        self.vectorized_kbase, self.class_indexes = self.vectorize_knowledge_base()\n",
    "    \n",
    "    def vectorize(self, data):\n",
    "        \"\"\"\n",
    "        Turns a list of N strings into their vector representation using self.w2v_model.\n",
    "        In the simplest case, averages the word vectors of all words in a sentence.\n",
    "        Returns a a matrix of shape [N, 300]\n",
    "        \"\"\"\n",
    "        vectorized = []\n",
    "        for d in data:\n",
    "            vectorized.append(bow_encoder(self.w2v_model, self.tokenize_and_lemmatize, d))\n",
    "        \n",
    "        return np.array(vectorized)\n",
    "        \n",
    "    def vectorize_knowledge_base(self):\n",
    "        \"\"\"\n",
    "        Vectorizes all questions AND paraphrased questions using the vectorize function.\n",
    "        Builds a list containing class id (it's index in self.knowledge_base) for each vectorized question.\n",
    "        \n",
    "        Example: you vectorized 1 question and 5 paraphrases for that question\n",
    "        Then you should append the ID of the question to class_labels list 5+1=6 times.\n",
    "        \"\"\"\n",
    "        vectors = []\n",
    "        class_labels = []\n",
    "        \n",
    "        # your code goes here\n",
    "        \n",
    "        return np.vstack(vectors), class_labels\n",
    "    \n",
    "    def compute_class_scores(self, similarities):\n",
    "        \"\"\"\n",
    "        Accepts an array of similarities of shape (self.class_indexes, )\n",
    "        Computes scores for classes.\n",
    "        Returns a dictionary of size (n_classes) that looks like\n",
    "        {\n",
    "            0: 0.3,\n",
    "            1: 0.1,\n",
    "            2: 0.0,\n",
    "            class_n_id: class_n_score\n",
    "            ...\n",
    "        }\n",
    "        \"\"\"\n",
    "        \n",
    "        class_scores = dict(zip(range(len(self.answers)), [0]*len(self.answers)))\n",
    "        \n",
    "        # your code goes here\n",
    "        return class_scores\n",
    "        \n",
    "    def tokenize_and_lemmatize(self, text):\n",
    "        analysis = self.lemmatizer.analyze(text.strip())\n",
    "        tokens = []\n",
    "        for an in analysis:\n",
    "            if 'analysis' in an:\n",
    "                try:\n",
    "                    tokens.append(an['analysis'][0]['lex'])\n",
    "                except IndexError:\n",
    "                    tokens.append(an['text'])\n",
    "        return tokens\n",
    "    \n",
    "    def get_top(self, query, top_k=3):\n",
    "        if isinstance(query, str):\n",
    "            query = [query]\n",
    "            \n",
    "        vectorized_query = self.vectorize(query)\n",
    "        css = cosine_similarity(vectorized_query, self.vectorized_kbase)[0]\n",
    "        scores = self.compute_class_scores(css)\n",
    "        \n",
    "        sorted_scores = sorted(scores.items(), key= lambda x: x[1])[::-1][:top_k]\n",
    "        top_classes = np.array([c[0] for c in sorted_scores])\n",
    "        top_answers = list(self.answers[top_classes])\n",
    "        return top_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Finally, integrate your best model with your telegram frontend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure config.py contains your valid bot token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from telegram.ext import Updater, CommandHandler, MessageHandler, Filters\n",
    "\n",
    "from config import TOKEN, LOG_FILE\n",
    "\n",
    "\n",
    "# Enable logging\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# Logging to file\n",
    "fh = logging.FileHandler(LOG_FILE)\n",
    "fh.setLevel(logging.DEBUG)\n",
    "fh.setFormatter(formatter)\n",
    "# Logging to console\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.DEBUG)\n",
    "ch.setFormatter(formatter)\n",
    "\n",
    "logger.addHandler(fh)\n",
    "logger.addHandler(ch)\n",
    "\n",
    "\n",
    "class Bot:\n",
    "    def __init__(self):\n",
    "\n",
    "        self.updater = Updater(TOKEN)\n",
    "        self.dsp = self.updater.dispatcher\n",
    "\n",
    "        # register handler functions which define how the bot reacts to events\n",
    "        self.dsp.add_handler(CommandHandler(\"start\", get_help))\n",
    "        self.dsp.add_handler(CommandHandler(\"help\", get_help))\n",
    "        self.dsp.add_handler(CommandHandler(\"sentiment\", get_sentiment))\n",
    "        self.dsp.add_handler(CommandHandler(\"answer\", get_answer))\n",
    "        self.dsp.add_handler(MessageHandler(Filters.text, echo))\n",
    "        self.dsp.add_error_handler(error)\n",
    "\n",
    "        logger.info('Im alive!')\n",
    "\n",
    "    def power_on(self):\n",
    "        # start the Bot\n",
    "        self.updater.start_polling()\n",
    "        self.updater.idle()\n",
    "\n",
    "# define command handlers. These usually take the two arguments: bot and\n",
    "# update. Error handlers also receive the raised TelegramError object in error.\n",
    "\n",
    "\n",
    "def echo(bot, update):\n",
    "    logger.info('echo recieved message: {}'.format(update.message.text))\n",
    "    bot.sendMessage(update.message.chat_id, text=update.message.text)\n",
    "\n",
    "\n",
    "def error(bot, update, error):\n",
    "    # all uncaught telegram-related exceptions will be rerouted here\n",
    "    logger.error('Update \"%s\" caused error \"%s\"' % (update, error))\n",
    "\n",
    "\n",
    "def get_help(bot, update):\n",
    "    logger.info('get_help recieved message: {}'.format(update.message.text))\n",
    "    help_msg = ('Greetings, {} {}! Name is {}, at your service.\\n'\n",
    "                'I currently support the following commands:\\n'\n",
    "                '/start - begins our chat and prints this message\\n'\n",
    "                '/help - prints this message\\n'\n",
    "                '/sentiment [message] - predicts the sentiment of the message').format(\n",
    "        update.message.from_user.first_name, update.message.from_user.last_name, bot.name)\n",
    "    bot.sendMessage(update.message.chat_id, text=help_msg)\n",
    "\n",
    "\n",
    "def get_sentiment(bot, update):\n",
    "    logger.info('get_sentiment recieved message: {}'.format(update.message.text))\n",
    "    try:\n",
    "        # get message text without the command '/sentiment'\n",
    "        usr_msg = update.message.text.split(' ', maxsplit=1)[1]\n",
    "        msg_sentiment = 0.5\n",
    "        '''\n",
    "        Now determine the sentiment of usr_msg.\n",
    "        This should return a real number in [0,1].\n",
    "        Your code goes here.\n",
    "        '''\n",
    "        bot.sendMessage(update.message.chat_id, text=msg_sentiment)\n",
    "    except IndexError:\n",
    "        bot.sendMessage(update.message.chat_id, text='Write your message after the command')\n",
    "    except Exception as e:\n",
    "        logger.error(e)\n",
    "        \n",
    "def get_answer(bot, update):\n",
    "    logger.info('get_answer recieved message: {}'.format(update.message.text))\n",
    "    try:\n",
    "        # get message text without the command \n",
    "        usr_msg = update.message.text.split(' ', maxsplit=1)[1]\n",
    "        # your code goes here\n",
    "        '''\n",
    "        Now determine the sentiment of usr_msg.\n",
    "        This should return a real number in [0,1].\n",
    "        Your code goes here.\n",
    "        '''\n",
    "        bot.sendMessage(update.message.chat_id, text=answer)\n",
    "    except IndexError:\n",
    "        bot.sendMessage(update.message.chat_id, text='Write your message after the command')\n",
    "    except Exception as e:\n",
    "        logger.error(e)\n",
    "\n",
    "my_bot = Bot()\n",
    "my_bot.power_on()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
