{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from gensim.models import KeyedVectors\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentiment_data = pd.read_csv(\"./train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_TO_USE = 250000\n",
    "\n",
    "texts = sentiment_data['message'].tolist()[:DATA_TO_USE]\n",
    "labels = np.array(sentiment_data['sentiment'])[:DATA_TO_USE]\n",
    "\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: word vectors meet bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you use your newly trained word vectors and a simple Bag of Words models to approach the sentiment analysis task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We will use a convinient wrapper for our word2vec model provided by gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_model = KeyedVectors.load_word2vec_format(\"./simple_cbow.w2v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0688487 , -0.169258  , -0.0235873 ,  0.0768677 , -0.0560077 ,\n",
       "       -0.20571201,  0.0722242 , -0.0238068 ,  0.0942261 ,  0.0445618 ,\n",
       "       -0.0930745 , -0.132294  , -0.0380145 , -0.0885391 ,  0.0289901 ,\n",
       "        0.0770231 , -0.122311  , -0.0118321 ,  0.13177601, -0.0227252 ,\n",
       "        0.16474199, -0.0572786 ,  0.0745815 , -0.0760634 ,  0.0295188 ,\n",
       "       -0.0441017 , -0.0895143 , -0.0566907 ,  0.0281097 , -0.00958456,\n",
       "       -0.110452  ,  0.0415194 , -0.0153895 , -0.0745323 ,  0.00762951,\n",
       "       -0.0319146 , -0.0557301 , -0.0886996 ,  0.0806743 , -0.0471586 ,\n",
       "       -0.0859856 , -0.20486601, -0.118638  ,  0.111954  ,  0.0344212 ,\n",
       "       -0.0233198 ,  0.0737764 ,  0.0346345 , -0.0558539 , -0.211096  ,\n",
       "       -0.0435312 ,  0.115727  , -0.0596598 , -0.0322688 , -0.0538118 ,\n",
       "        0.0722077 ,  0.0208389 , -0.15472899,  0.0143741 , -0.126031  ,\n",
       "        0.0622076 ,  0.032778  ,  0.0305527 ,  0.0810955 ,  0.010537  ,\n",
       "        0.0163742 , -0.0827605 , -0.0131961 ,  0.0289909 , -0.0646999 ,\n",
       "       -0.0708455 ,  0.0939854 ,  0.166179  ,  0.155966  , -0.0936102 ,\n",
       "        0.00879914,  0.0360047 ,  0.0902226 , -0.0187742 , -0.0600839 ,\n",
       "        0.0391964 , -0.0975536 , -0.0356622 , -0.0324537 ,  0.104185  ,\n",
       "        0.130004  , -0.13667101, -0.104945  , -0.0836355 ,  0.0663564 ,\n",
       "        0.0790161 , -0.0118584 ,  0.00110292, -0.075322  ,  0.0269967 ,\n",
       "       -0.0704023 , -0.0582241 ,  0.0780745 ,  0.0583372 , -0.116921  ,\n",
       "       -0.0298988 , -0.0849007 ,  0.13700899, -0.0846834 , -0.12925801,\n",
       "        0.00485594,  0.063532  , -0.0317335 ,  0.102577  , -0.0772568 ,\n",
       "       -0.17413101, -0.0858324 , -0.13659699, -0.00087295,  0.00115875,\n",
       "       -0.0277262 ,  0.0650055 , -0.0741444 ,  0.05642   , -0.126343  ,\n",
       "       -0.0656122 ,  0.203464  , -0.0750102 ,  0.0168465 , -0.0828873 ,\n",
       "       -0.135879  ,  0.0356199 ,  0.22182199], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can get the vector for a word in a simple way\n",
    "w2v_model['word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cool', 0.5530734062194824),\n",
       " ('good', 0.4626672565937042),\n",
       " ('nice', 0.44066357612609863),\n",
       " ('awesome', 0.438425213098526),\n",
       " ('exciting', 0.43373095989227295),\n",
       " ('weird', 0.43178021907806396),\n",
       " ('cute', 0.40261897444725037),\n",
       " ('interesting', 0.3848278522491455),\n",
       " ('awesome!', 0.3723982572555542),\n",
       " ('amazing', 0.36828142404556274)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can easily query the model for word most similar to a give word \n",
    "w2v_model.most_similar('funny')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you learn how to encode sentences with word2vec using a bag of words approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# implement a tokenizer that you will use throughout the exercise\n",
    "# I would recommend a regexp tokenizer for speed, but it's completely up to you\n",
    "def my_tokenizer(text):\n",
    "    return nltk.regexp_tokenize(text, '\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bow_encoder(wmodel, tokenizer, text):\n",
    "    \"\"\"\n",
    "    This function encodes text into a vector.\n",
    "    \n",
    "    First, it tokenizes input text using the provided tokenizer function.\n",
    "    Then it uses the provided word2vec model to get the vectors corresponding to text's tokens.\n",
    "    Finally, it computes an average of all token's vectors and returns it.\n",
    "    \n",
    "    If the function failed to find and encode any words, it should at least return a vector of zeros.\n",
    "    \"\"\"\n",
    "    tokens = tokenizer(text)\n",
    "    \n",
    "    zero_vector = np.zeros(w2v_model.vector_size)\n",
    "    word_vectors = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token in wmodel:\n",
    "            word_vectors.append(wmodel[token]*tfidfmodel[token])\n",
    "            \n",
    "    if len(word_vectors):\n",
    "        sent_vector = np.mean(word_vectors, axis=0)\n",
    "    else:\n",
    "        sent_vector = zero_vector\n",
    "    # your code goes here\n",
    "    return sent_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use your new encoder to encode both train_texts and test_texts into matrices.\n",
    "\n",
    "The number of rows in a matrix should be equal to the number of texts encoded.\n",
    "\n",
    "The number of columns should be equal to the word2vec space dimansionality (currently = 128)\n",
    "\n",
    "Just write a little loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_sentences_with_bow_encoder(sentences, w2v_model, tokenizer):\n",
    "    return np.array([bow_encoder(w2v_model, my_tokenizer, t) \n",
    "                     for t in tqdm(sentences)] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/187500 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 818/187500 [00:00<00:22, 8175.66it/s]\u001b[A\n",
      "  1%|          | 1589/187500 [00:00<00:23, 8028.30it/s]\u001b[A\n",
      "  1%|▏         | 2366/187500 [00:00<00:23, 7946.98it/s]\u001b[A\n",
      "  2%|▏         | 3181/187500 [00:00<00:23, 8005.82it/s]\u001b[A\n",
      "  2%|▏         | 4052/187500 [00:00<00:22, 8203.64it/s]\u001b[A\n",
      "  3%|▎         | 4894/187500 [00:00<00:22, 8266.62it/s]\u001b[A\n",
      "  3%|▎         | 5626/187500 [00:00<00:28, 6291.58it/s]\u001b[A\n",
      "  3%|▎         | 6260/187500 [00:00<00:29, 6127.84it/s]\u001b[A\n",
      "  4%|▎         | 6963/187500 [00:00<00:28, 6290.14it/s]\u001b[A\n",
      "  4%|▍         | 7710/187500 [00:01<00:27, 6602.11it/s]\u001b[A\n",
      "  4%|▍         | 8393/187500 [00:01<00:26, 6667.18it/s]\u001b[A\n",
      "  5%|▍         | 9065/187500 [00:01<00:28, 6316.46it/s]\u001b[A\n",
      "  5%|▌         | 9768/187500 [00:01<00:27, 6514.24it/s]\u001b[A\n",
      "  6%|▌         | 10427/187500 [00:01<00:28, 6300.35it/s]\u001b[A\n",
      "  6%|▌         | 11091/187500 [00:01<00:27, 6397.93it/s]\u001b[A\n",
      "  6%|▋         | 11910/187500 [00:01<00:25, 6846.92it/s]\u001b[A\n",
      "  7%|▋         | 12607/187500 [00:01<00:25, 6872.43it/s]\u001b[A\n",
      "  7%|▋         | 13303/187500 [00:01<00:25, 6893.79it/s]\u001b[A\n",
      "  8%|▊         | 14067/187500 [00:02<00:24, 7099.77it/s]\u001b[A\n",
      "  8%|▊         | 14899/187500 [00:02<00:23, 7426.51it/s]\u001b[A\n",
      "  8%|▊         | 15650/187500 [00:02<00:23, 7425.10it/s]\u001b[A\n",
      "  9%|▊         | 16399/187500 [00:02<00:23, 7301.14it/s]\u001b[A\n",
      "  9%|▉         | 17276/187500 [00:02<00:22, 7686.03it/s]\u001b[A\n",
      " 10%|▉         | 18115/187500 [00:02<00:21, 7884.43it/s]\u001b[A\n",
      " 10%|█         | 18911/187500 [00:02<00:21, 7765.05it/s]\u001b[A\n",
      " 11%|█         | 19693/187500 [00:02<00:22, 7575.73it/s]\u001b[A\n",
      " 11%|█         | 20456/187500 [00:02<00:22, 7474.90it/s]\u001b[A\n",
      " 11%|█▏        | 21208/187500 [00:02<00:24, 6892.41it/s]\u001b[A\n",
      " 12%|█▏        | 21909/187500 [00:03<00:24, 6697.96it/s]\u001b[A\n",
      " 12%|█▏        | 22589/187500 [00:03<00:24, 6722.48it/s]\u001b[A\n",
      " 12%|█▏        | 23325/187500 [00:03<00:23, 6899.48it/s]\u001b[A\n",
      " 13%|█▎        | 24035/187500 [00:03<00:23, 6956.76it/s]\u001b[A\n",
      " 13%|█▎        | 24813/187500 [00:03<00:22, 7182.87it/s]\u001b[A\n",
      " 14%|█▎        | 25537/187500 [00:03<00:22, 7171.12it/s]\u001b[A\n",
      " 14%|█▍        | 26258/187500 [00:03<00:23, 6791.75it/s]\u001b[A\n",
      " 14%|█▍        | 26944/187500 [00:03<00:24, 6540.30it/s]\u001b[A\n",
      " 15%|█▍        | 27605/187500 [00:03<00:26, 6004.60it/s]\u001b[A\n",
      " 15%|█▌        | 28336/187500 [00:04<00:25, 6343.36it/s]\u001b[A\n",
      " 16%|█▌        | 29194/187500 [00:04<00:23, 6881.16it/s]\u001b[A\n",
      " 16%|█▌        | 30022/187500 [00:04<00:21, 7246.91it/s]\u001b[A\n",
      " 16%|█▋        | 30833/187500 [00:04<00:20, 7483.99it/s]\u001b[A\n",
      " 17%|█▋        | 31599/187500 [00:04<00:21, 7411.86it/s]\u001b[A\n",
      " 17%|█▋        | 32353/187500 [00:04<00:21, 7328.73it/s]\u001b[A\n",
      " 18%|█▊        | 33139/187500 [00:04<00:20, 7477.38it/s]\u001b[A\n",
      " 18%|█▊        | 33942/187500 [00:04<00:20, 7634.01it/s]\u001b[A\n",
      " 19%|█▊        | 34726/187500 [00:04<00:19, 7693.42it/s]\u001b[A\n",
      " 19%|█▉        | 35500/187500 [00:04<00:19, 7619.56it/s]\u001b[A\n",
      " 19%|█▉        | 36325/187500 [00:05<00:19, 7798.20it/s]\u001b[A\n",
      " 20%|█▉        | 37108/187500 [00:05<00:19, 7637.97it/s]\u001b[A\n",
      " 20%|██        | 37875/187500 [00:05<00:22, 6773.10it/s]\u001b[A\n",
      " 21%|██        | 38573/187500 [00:05<00:22, 6601.28it/s]\u001b[A\n",
      " 21%|██        | 39249/187500 [00:05<00:22, 6455.39it/s]\u001b[A\n",
      " 21%|██▏       | 39906/187500 [00:05<00:23, 6274.39it/s]\u001b[A\n",
      " 22%|██▏       | 40706/187500 [00:05<00:21, 6707.86it/s]\u001b[A\n",
      " 22%|██▏       | 41539/187500 [00:05<00:20, 7115.47it/s]\u001b[A\n",
      " 23%|██▎       | 42268/187500 [00:05<00:21, 6816.31it/s]\u001b[A\n",
      " 23%|██▎       | 42965/187500 [00:06<00:22, 6519.64it/s]\u001b[A\n",
      " 23%|██▎       | 43630/187500 [00:06<00:22, 6377.21it/s]\u001b[A\n",
      " 24%|██▎       | 44379/187500 [00:06<00:21, 6674.13it/s]\u001b[A\n",
      " 24%|██▍       | 45186/187500 [00:06<00:20, 7038.40it/s]\u001b[A\n",
      " 25%|██▍       | 45987/187500 [00:06<00:19, 7303.40it/s]\u001b[A\n",
      " 25%|██▍       | 46791/187500 [00:06<00:18, 7507.85it/s]\u001b[A\n",
      " 25%|██▌       | 47643/187500 [00:06<00:17, 7784.99it/s]\u001b[A\n",
      " 26%|██▌       | 48431/187500 [00:06<00:19, 7301.13it/s]\u001b[A\n",
      " 26%|██▌       | 49174/187500 [00:06<00:19, 7130.71it/s]\u001b[A\n",
      " 27%|██▋       | 49897/187500 [00:07<00:19, 6893.15it/s]\u001b[A\n",
      " 27%|██▋       | 50595/187500 [00:07<00:22, 6056.51it/s]\u001b[A\n",
      " 27%|██▋       | 51226/187500 [00:07<00:22, 5941.94it/s]\u001b[A\n",
      " 28%|██▊       | 51933/187500 [00:07<00:21, 6239.17it/s]\u001b[A\n",
      " 28%|██▊       | 52731/187500 [00:07<00:20, 6673.93it/s]\u001b[A\n",
      " 28%|██▊       | 53419/187500 [00:07<00:20, 6664.11it/s]\u001b[A\n",
      " 29%|██▉       | 54189/187500 [00:07<00:19, 6942.93it/s]\u001b[A\n",
      " 29%|██▉       | 54966/187500 [00:07<00:18, 7170.76it/s]\u001b[A\n",
      " 30%|██▉       | 55694/187500 [00:07<00:18, 7190.36it/s]\u001b[A\n",
      " 30%|███       | 56421/187500 [00:08<00:20, 6460.20it/s]\u001b[A\n",
      " 30%|███       | 57087/187500 [00:08<00:21, 6040.83it/s]\u001b[A\n",
      " 31%|███       | 57711/187500 [00:08<00:22, 5871.19it/s]\u001b[A\n",
      " 31%|███       | 58313/187500 [00:08<00:22, 5665.01it/s]\u001b[A\n",
      " 31%|███▏      | 58944/187500 [00:08<00:22, 5843.05it/s]\u001b[A\n",
      " 32%|███▏      | 59538/187500 [00:08<00:23, 5548.40it/s]\u001b[A\n",
      " 32%|███▏      | 60227/187500 [00:08<00:21, 5891.57it/s]\u001b[A\n",
      " 33%|███▎      | 61007/187500 [00:08<00:19, 6358.12it/s]\u001b[A\n",
      " 33%|███▎      | 61789/187500 [00:08<00:18, 6735.57it/s]\u001b[A\n",
      " 33%|███▎      | 62483/187500 [00:09<00:18, 6773.38it/s]\u001b[A\n",
      " 34%|███▍      | 63367/187500 [00:09<00:17, 7284.13it/s]\u001b[A\n",
      " 34%|███▍      | 64116/187500 [00:09<00:17, 7164.92it/s]\u001b[A\n",
      " 35%|███▍      | 64848/187500 [00:09<00:18, 6749.77it/s]\u001b[A\n",
      " 35%|███▍      | 65539/187500 [00:09<00:18, 6587.27it/s]\u001b[A\n",
      " 35%|███▌      | 66210/187500 [00:09<00:19, 6235.22it/s]\u001b[A\n",
      " 36%|███▌      | 66890/187500 [00:09<00:18, 6393.26it/s]\u001b[A\n",
      " 36%|███▌      | 67601/187500 [00:09<00:18, 6591.21it/s]\u001b[A\n",
      " 36%|███▋      | 68269/187500 [00:09<00:18, 6498.24it/s]\u001b[A\n",
      " 37%|███▋      | 68927/187500 [00:10<00:18, 6522.21it/s]\u001b[A\n",
      " 37%|███▋      | 69848/187500 [00:10<00:16, 7147.01it/s]\u001b[A\n",
      " 38%|███▊      | 70584/187500 [00:10<00:17, 6869.04it/s]\u001b[A\n",
      " 38%|███▊      | 71288/187500 [00:10<00:19, 5918.90it/s]\u001b[A\n",
      " 38%|███▊      | 71915/187500 [00:10<00:20, 5713.69it/s]\u001b[A\n",
      " 39%|███▉      | 72678/187500 [00:10<00:18, 6178.21it/s]\u001b[A\n",
      " 39%|███▉      | 73325/187500 [00:10<00:18, 6021.21it/s]\u001b[A\n",
      " 40%|███▉      | 74077/187500 [00:10<00:17, 6403.63it/s]\u001b[A\n",
      " 40%|███▉      | 74848/187500 [00:10<00:16, 6741.58it/s]\u001b[A\n",
      " 40%|████      | 75641/187500 [00:11<00:15, 7057.55it/s]\u001b[A\n",
      " 41%|████      | 76435/187500 [00:11<00:15, 7299.59it/s]\u001b[A\n",
      " 41%|████      | 77180/187500 [00:11<00:15, 7031.09it/s]\u001b[A\n",
      " 42%|████▏     | 77992/187500 [00:11<00:14, 7323.73it/s]\u001b[A\n",
      " 42%|████▏     | 78789/187500 [00:11<00:14, 7504.99it/s]\u001b[A\n",
      " 42%|████▏     | 79549/187500 [00:11<00:16, 6656.40it/s]\u001b[A\n",
      " 43%|████▎     | 80239/187500 [00:11<00:16, 6379.33it/s]\u001b[A\n",
      " 43%|████▎     | 80897/187500 [00:11<00:18, 5696.93it/s]\u001b[A\n",
      " 43%|████▎     | 81544/187500 [00:11<00:17, 5908.14it/s]\u001b[A\n",
      " 44%|████▍     | 82223/187500 [00:12<00:17, 6146.94it/s]\u001b[A\n",
      " 44%|████▍     | 82879/187500 [00:12<00:16, 6262.22it/s]\u001b[A\n",
      " 45%|████▍     | 83518/187500 [00:12<00:16, 6227.30it/s]\u001b[A\n",
      " 45%|████▍     | 84252/187500 [00:12<00:15, 6520.69it/s]\u001b[A\n",
      " 45%|████▌     | 84996/187500 [00:12<00:15, 6771.70it/s]\u001b[A\n",
      " 46%|████▌     | 85683/187500 [00:12<00:15, 6462.47it/s]\u001b[A\n",
      " 46%|████▌     | 86339/187500 [00:12<00:15, 6323.50it/s]\u001b[A\n",
      " 46%|████▋     | 86979/187500 [00:12<00:16, 6154.62it/s]\u001b[A\n",
      " 47%|████▋     | 87722/187500 [00:12<00:15, 6486.00it/s]\u001b[A\n",
      " 47%|████▋     | 88628/187500 [00:12<00:13, 7089.57it/s]\u001b[A\n",
      " 48%|████▊     | 89445/187500 [00:13<00:13, 7378.29it/s]\u001b[A\n",
      " 48%|████▊     | 90246/187500 [00:13<00:12, 7555.87it/s]\u001b[A\n",
      " 49%|████▊     | 91017/187500 [00:13<00:12, 7439.72it/s]\u001b[A\n",
      " 49%|████▉     | 91772/187500 [00:13<00:13, 7192.73it/s]\u001b[A\n",
      " 49%|████▉     | 92501/187500 [00:13<00:13, 7089.68it/s]\u001b[A\n",
      " 50%|████▉     | 93287/187500 [00:13<00:12, 7304.14it/s]\u001b[A\n",
      " 50%|█████     | 94227/187500 [00:13<00:11, 7826.73it/s]\u001b[A\n",
      " 51%|█████     | 95128/187500 [00:13<00:11, 8147.38it/s]\u001b[A\n",
      " 51%|█████     | 95973/187500 [00:13<00:11, 8230.86it/s]\u001b[A\n",
      " 52%|█████▏    | 96806/187500 [00:14<00:11, 8197.85it/s]\u001b[A\n",
      " 52%|█████▏    | 97633/187500 [00:14<00:11, 8145.63it/s]\u001b[A\n",
      " 53%|█████▎    | 98453/187500 [00:14<00:11, 8062.34it/s]\u001b[A\n",
      " 53%|█████▎    | 99280/187500 [00:14<00:10, 8121.74it/s]\u001b[A\n",
      " 53%|█████▎    | 100095/187500 [00:14<00:11, 7820.42it/s]\u001b[A\n",
      " 54%|█████▍    | 100882/187500 [00:14<00:12, 6984.33it/s]\u001b[A\n",
      " 54%|█████▍    | 101648/187500 [00:14<00:11, 7174.13it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 102527/187500 [00:14<00:11, 7590.61it/s]\u001b[A\n",
      " 55%|█████▌    | 103313/187500 [00:14<00:10, 7667.61it/s]\u001b[A\n",
      " 56%|█████▌    | 104122/187500 [00:14<00:10, 7789.55it/s]\u001b[A\n",
      " 56%|█████▌    | 104974/187500 [00:15<00:10, 7994.18it/s]\u001b[A\n",
      " 56%|█████▋    | 105782/187500 [00:15<00:10, 7705.36it/s]\u001b[A\n",
      " 57%|█████▋    | 106561/187500 [00:15<00:10, 7382.19it/s]\u001b[A\n",
      " 57%|█████▋    | 107350/187500 [00:15<00:10, 7525.57it/s]\u001b[A\n",
      " 58%|█████▊    | 108181/187500 [00:15<00:10, 7744.87it/s]\u001b[A\n",
      " 58%|█████▊    | 109044/187500 [00:15<00:09, 7989.99it/s]\u001b[A\n",
      " 59%|█████▊    | 109875/187500 [00:15<00:09, 8081.91it/s]\u001b[A\n",
      " 59%|█████▉    | 110692/187500 [00:15<00:09, 8106.52it/s]\u001b[A\n",
      " 59%|█████▉    | 111538/187500 [00:15<00:09, 8207.53it/s]\u001b[A\n",
      " 60%|█████▉    | 112406/187500 [00:15<00:09, 8342.58it/s]\u001b[A\n",
      " 60%|██████    | 113258/187500 [00:16<00:08, 8394.78it/s]\u001b[A\n",
      " 61%|██████    | 114100/187500 [00:16<00:08, 8200.00it/s]\u001b[A\n",
      " 61%|██████▏   | 114923/187500 [00:16<00:11, 6253.00it/s]\u001b[A\n",
      " 62%|██████▏   | 115620/187500 [00:16<00:16, 4477.72it/s]\u001b[A\n",
      " 62%|██████▏   | 116276/187500 [00:16<00:14, 4948.56it/s]\u001b[A\n",
      " 62%|██████▏   | 116871/187500 [00:17<00:19, 3714.74it/s]\u001b[A\n",
      " 63%|██████▎   | 117601/187500 [00:17<00:16, 4356.11it/s]\u001b[A\n",
      " 63%|██████▎   | 118503/187500 [00:17<00:13, 5155.19it/s]\u001b[A\n",
      " 64%|██████▎   | 119363/187500 [00:17<00:11, 5859.26it/s]\u001b[A\n",
      " 64%|██████▍   | 120350/187500 [00:17<00:10, 6672.39it/s]\u001b[A\n",
      " 65%|██████▍   | 121249/187500 [00:17<00:09, 7230.22it/s]\u001b[A\n",
      " 65%|██████▌   | 122080/187500 [00:17<00:08, 7422.12it/s]\u001b[A\n",
      " 66%|██████▌   | 123003/187500 [00:17<00:08, 7885.37it/s]\u001b[A\n",
      " 66%|██████▌   | 124016/187500 [00:17<00:07, 8446.14it/s]\u001b[A\n",
      " 67%|██████▋   | 125021/187500 [00:17<00:07, 8870.02it/s]\u001b[A\n",
      " 67%|██████▋   | 125952/187500 [00:18<00:06, 8989.81it/s]\u001b[A\n",
      " 68%|██████▊   | 126882/187500 [00:18<00:06, 8696.43it/s]\u001b[A\n",
      " 68%|██████▊   | 127776/187500 [00:18<00:07, 8485.38it/s]\u001b[A\n",
      " 69%|██████▊   | 128768/187500 [00:18<00:06, 8867.60it/s]\u001b[A\n",
      " 69%|██████▉   | 129752/187500 [00:18<00:06, 9138.47it/s]\u001b[A\n",
      " 70%|██████▉   | 130680/187500 [00:18<00:06, 9033.16it/s]\u001b[A\n",
      " 70%|███████   | 131615/187500 [00:18<00:06, 9120.56it/s]\u001b[A\n",
      " 71%|███████   | 132581/187500 [00:18<00:05, 9274.81it/s]\u001b[A\n",
      " 71%|███████   | 133531/187500 [00:18<00:05, 9337.46it/s]\u001b[A\n",
      " 72%|███████▏  | 134469/187500 [00:18<00:05, 9129.80it/s]\u001b[A\n",
      " 72%|███████▏  | 135405/187500 [00:19<00:05, 9197.17it/s]\u001b[A\n",
      " 73%|███████▎  | 136373/187500 [00:19<00:05, 9333.84it/s]\u001b[A\n",
      " 73%|███████▎  | 137309/187500 [00:19<00:05, 9019.49it/s]\u001b[A\n",
      " 74%|███████▎  | 138226/187500 [00:19<00:05, 9061.33it/s]\u001b[A\n",
      " 74%|███████▍  | 139167/187500 [00:19<00:05, 9162.97it/s]\u001b[A\n",
      " 75%|███████▍  | 140201/187500 [00:19<00:04, 9484.91it/s]\u001b[A\n",
      " 75%|███████▌  | 141154/187500 [00:19<00:05, 9225.82it/s]\u001b[A\n",
      " 76%|███████▌  | 142082/187500 [00:19<00:05, 8900.69it/s]\u001b[A\n",
      " 76%|███████▋  | 142978/187500 [00:19<00:05, 8788.99it/s]\u001b[A\n",
      " 77%|███████▋  | 143962/187500 [00:20<00:04, 9077.55it/s]\u001b[A\n",
      " 77%|███████▋  | 144876/187500 [00:20<00:04, 8802.35it/s]\u001b[A\n",
      " 78%|███████▊  | 145762/187500 [00:20<00:04, 8766.45it/s]\u001b[A\n",
      " 78%|███████▊  | 146715/187500 [00:20<00:04, 8979.30it/s]\u001b[A\n",
      " 79%|███████▊  | 147617/187500 [00:20<00:04, 8905.85it/s]\u001b[A\n",
      " 79%|███████▉  | 148542/187500 [00:20<00:04, 9005.82it/s]\u001b[A\n",
      " 80%|███████▉  | 149445/187500 [00:20<00:04, 8969.44it/s]\u001b[A\n",
      " 80%|████████  | 150344/187500 [00:20<00:04, 8813.72it/s]\u001b[A\n",
      " 81%|████████  | 151228/187500 [00:20<00:04, 8485.16it/s]\u001b[A\n",
      " 81%|████████  | 152081/187500 [00:20<00:04, 8464.30it/s]\u001b[A\n",
      " 82%|████████▏ | 152931/187500 [00:21<00:04, 8443.51it/s]\u001b[A\n",
      " 82%|████████▏ | 153880/187500 [00:21<00:03, 8731.65it/s]\u001b[A\n",
      " 83%|████████▎ | 154758/187500 [00:21<00:03, 8217.73it/s]\u001b[A\n",
      " 83%|████████▎ | 155589/187500 [00:21<00:04, 7691.43it/s]\u001b[A\n",
      " 83%|████████▎ | 156455/187500 [00:21<00:03, 7957.91it/s]\u001b[A\n",
      " 84%|████████▍ | 157263/187500 [00:21<00:04, 7544.03it/s]\u001b[A\n",
      " 84%|████████▍ | 158060/187500 [00:21<00:03, 7663.69it/s]\u001b[A\n",
      " 85%|████████▍ | 158896/187500 [00:21<00:03, 7856.95it/s]\u001b[A\n",
      " 85%|████████▌ | 159787/187500 [00:21<00:03, 8144.09it/s]\u001b[A\n",
      " 86%|████████▌ | 160744/187500 [00:22<00:03, 8522.27it/s]\u001b[A\n",
      " 86%|████████▌ | 161619/187500 [00:22<00:03, 8588.88it/s]\u001b[A\n",
      " 87%|████████▋ | 162486/187500 [00:22<00:02, 8547.64it/s]\u001b[A\n",
      " 87%|████████▋ | 163346/187500 [00:22<00:02, 8414.53it/s]\u001b[A\n",
      " 88%|████████▊ | 164192/187500 [00:22<00:02, 8316.08it/s]\u001b[A\n",
      " 88%|████████▊ | 165027/187500 [00:22<00:02, 8028.63it/s]\u001b[A\n",
      " 88%|████████▊ | 165835/187500 [00:22<00:02, 8002.07it/s]\u001b[A\n",
      " 89%|████████▉ | 166661/187500 [00:22<00:02, 8061.24it/s]\u001b[A\n",
      " 89%|████████▉ | 167592/187500 [00:22<00:02, 8396.42it/s]\u001b[A\n",
      " 90%|████████▉ | 168452/187500 [00:22<00:02, 8456.43it/s]\u001b[A\n",
      " 90%|█████████ | 169316/187500 [00:23<00:02, 8510.25it/s]\u001b[A\n",
      " 91%|█████████ | 170170/187500 [00:23<00:02, 7883.12it/s]\u001b[A\n",
      " 91%|█████████ | 170971/187500 [00:23<00:02, 7919.82it/s]\u001b[A\n",
      " 92%|█████████▏| 171824/187500 [00:23<00:01, 8091.23it/s]\u001b[A\n",
      " 92%|█████████▏| 172814/187500 [00:23<00:01, 8557.04it/s]\u001b[A\n",
      " 93%|█████████▎| 173682/187500 [00:23<00:01, 8446.33it/s]\u001b[A\n",
      " 93%|█████████▎| 174536/187500 [00:23<00:01, 8342.84it/s]\u001b[A\n",
      " 94%|█████████▎| 175377/187500 [00:23<00:01, 8257.00it/s]\u001b[A\n",
      " 94%|█████████▍| 176259/187500 [00:23<00:01, 8409.08it/s]\u001b[A\n",
      " 94%|█████████▍| 177181/187500 [00:23<00:01, 8634.33it/s]\u001b[A\n",
      " 95%|█████████▍| 178064/187500 [00:24<00:01, 8688.98it/s]\u001b[A\n",
      " 95%|█████████▌| 178972/187500 [00:24<00:00, 8800.50it/s]\u001b[A\n",
      " 96%|█████████▌| 179897/187500 [00:24<00:00, 8930.00it/s]\u001b[A\n",
      " 96%|█████████▋| 180827/187500 [00:24<00:00, 9037.71it/s]\u001b[A\n",
      " 97%|█████████▋| 181775/187500 [00:24<00:00, 9165.71it/s]\u001b[A\n",
      " 97%|█████████▋| 182694/187500 [00:24<00:00, 8686.77it/s]\u001b[A\n",
      " 98%|█████████▊| 183627/187500 [00:24<00:00, 8866.99it/s]\u001b[A\n",
      " 98%|█████████▊| 184520/187500 [00:24<00:00, 8657.30it/s]\u001b[A\n",
      " 99%|█████████▉| 185391/187500 [00:24<00:00, 8611.38it/s]\u001b[A\n",
      " 99%|█████████▉| 186256/187500 [00:25<00:00, 8525.48it/s]\u001b[A\n",
      "100%|█████████▉| 187121/187500 [00:25<00:00, 8561.19it/s]\u001b[A\n",
      "100%|██████████| 187500/187500 [00:25<00:00, 7450.69it/s]\u001b[A\n",
      "  0%|          | 0/62500 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 424/62500 [00:00<00:14, 4239.91it/s]\u001b[A\n",
      "  2%|▏         | 1141/62500 [00:00<00:12, 4831.65it/s]\u001b[A\n",
      "  3%|▎         | 1912/62500 [00:00<00:11, 5440.67it/s]\u001b[A\n",
      "  4%|▍         | 2659/62500 [00:00<00:10, 5923.23it/s]\u001b[A\n",
      "  6%|▌         | 3457/62500 [00:00<00:09, 6418.01it/s]\u001b[A\n",
      "  7%|▋         | 4232/62500 [00:00<00:08, 6766.37it/s]\u001b[A\n",
      "  8%|▊         | 4894/62500 [00:00<00:09, 6039.25it/s]\u001b[A\n",
      "  9%|▉         | 5591/62500 [00:00<00:09, 6291.20it/s]\u001b[A\n",
      " 10%|█         | 6370/62500 [00:00<00:08, 6673.84it/s]\u001b[A\n",
      " 11%|█▏        | 7048/62500 [00:01<00:08, 6673.13it/s]\u001b[A\n",
      " 12%|█▏        | 7786/62500 [00:01<00:08, 6263.24it/s]\u001b[A\n",
      " 13%|█▎        | 8423/62500 [00:01<00:14, 3853.28it/s]\u001b[A\n",
      " 14%|█▍        | 8930/62500 [00:01<00:15, 3486.43it/s]\u001b[A\n",
      " 15%|█▍        | 9371/62500 [00:01<00:18, 2882.07it/s]\u001b[A\n",
      " 16%|█▌        | 9741/62500 [00:02<00:19, 2691.92it/s]\u001b[A\n",
      " 16%|█▌        | 10070/62500 [00:02<00:34, 1523.21it/s]\u001b[A\n",
      " 17%|█▋        | 10398/62500 [00:02<00:28, 1814.03it/s]\u001b[A\n",
      " 17%|█▋        | 10699/62500 [00:02<00:25, 2048.22it/s]\u001b[A\n",
      " 18%|█▊        | 10980/62500 [00:02<00:24, 2124.22it/s]\u001b[A\n",
      " 18%|█▊        | 11270/62500 [00:02<00:22, 2308.92it/s]\u001b[A\n",
      " 19%|█▊        | 11582/62500 [00:02<00:20, 2503.73it/s]\u001b[A\n",
      " 19%|█▉        | 11899/62500 [00:03<00:18, 2671.68it/s]\u001b[A\n",
      " 20%|█▉        | 12194/62500 [00:03<00:27, 1828.17it/s]\u001b[A\n",
      " 20%|██        | 12515/62500 [00:03<00:23, 2099.26it/s]\u001b[A\n",
      " 21%|██        | 12943/62500 [00:03<00:20, 2447.39it/s]\u001b[A\n",
      " 21%|██▏       | 13307/62500 [00:03<00:18, 2705.25it/s]\u001b[A\n",
      " 22%|██▏       | 13628/62500 [00:03<00:22, 2132.57it/s]\u001b[A\n",
      " 22%|██▏       | 13960/62500 [00:04<00:20, 2388.33it/s]\u001b[A\n",
      " 23%|██▎       | 14306/62500 [00:04<00:18, 2632.10it/s]\u001b[A\n",
      " 23%|██▎       | 14624/62500 [00:04<00:17, 2773.54it/s]\u001b[A\n",
      " 24%|██▍       | 14946/62500 [00:04<00:16, 2889.42it/s]\u001b[A\n",
      " 24%|██▍       | 15258/62500 [00:04<00:16, 2857.56it/s]\u001b[A\n",
      " 25%|██▍       | 15603/62500 [00:04<00:15, 3010.01it/s]\u001b[A\n",
      " 26%|██▌       | 15943/62500 [00:04<00:14, 3114.88it/s]\u001b[A\n",
      " 26%|██▌       | 16316/62500 [00:04<00:14, 3276.21it/s]\u001b[A\n",
      " 27%|██▋       | 16670/62500 [00:04<00:13, 3350.76it/s]\u001b[A\n",
      " 27%|██▋       | 17113/62500 [00:04<00:12, 3614.49it/s]\u001b[A\n",
      " 28%|██▊       | 17698/62500 [00:05<00:10, 4081.97it/s]\u001b[A\n",
      " 29%|██▉       | 18134/62500 [00:05<00:11, 3999.10it/s]\u001b[A\n",
      " 30%|███       | 18783/62500 [00:05<00:09, 4517.13it/s]\u001b[A\n",
      " 31%|███       | 19470/62500 [00:05<00:08, 5033.42it/s]\u001b[A\n",
      " 32%|███▏      | 20037/62500 [00:05<00:08, 5208.75it/s]\u001b[A\n",
      " 33%|███▎      | 20770/62500 [00:05<00:07, 5703.49it/s]\u001b[A\n",
      " 34%|███▍      | 21489/62500 [00:05<00:06, 6079.17it/s]\u001b[A\n",
      " 35%|███▌      | 22130/62500 [00:05<00:06, 5861.10it/s]\u001b[A\n",
      " 36%|███▋      | 22783/62500 [00:05<00:06, 6045.71it/s]\u001b[A\n",
      " 37%|███▋      | 23407/62500 [00:05<00:06, 5916.47it/s]\u001b[A\n",
      " 39%|███▊      | 24098/62500 [00:06<00:06, 6181.06it/s]\u001b[A\n",
      " 40%|███▉      | 24729/62500 [00:06<00:06, 6110.22it/s]\u001b[A\n",
      " 41%|████      | 25379/62500 [00:06<00:05, 6209.87it/s]\u001b[A\n",
      " 42%|████▏     | 26223/62500 [00:06<00:05, 6743.88it/s]\u001b[A\n",
      " 43%|████▎     | 27041/62500 [00:06<00:04, 7118.79it/s]\u001b[A\n",
      " 45%|████▍     | 27888/62500 [00:06<00:04, 7474.86it/s]\u001b[A\n",
      " 46%|████▌     | 28676/62500 [00:06<00:04, 7591.94it/s]\u001b[A\n",
      " 47%|████▋     | 29517/62500 [00:06<00:04, 7819.31it/s]\u001b[A\n",
      " 49%|████▊     | 30452/62500 [00:06<00:03, 8223.07it/s]\u001b[A\n",
      " 50%|█████     | 31294/62500 [00:06<00:03, 8279.54it/s]\u001b[A\n",
      " 51%|█████▏    | 32132/62500 [00:07<00:03, 8212.51it/s]\u001b[A\n",
      " 53%|█████▎    | 33074/62500 [00:07<00:03, 8530.28it/s]\u001b[A\n",
      " 54%|█████▍    | 33935/62500 [00:07<00:03, 7384.58it/s]\u001b[A\n",
      " 56%|█████▌    | 34707/62500 [00:07<00:03, 7471.26it/s]\u001b[A\n",
      " 57%|█████▋    | 35611/62500 [00:07<00:03, 7879.21it/s]\u001b[A\n",
      " 58%|█████▊    | 36498/62500 [00:07<00:03, 8152.10it/s]\u001b[A\n",
      " 60%|█████▉    | 37409/62500 [00:07<00:02, 8413.58it/s]\u001b[A\n",
      " 61%|██████    | 38266/62500 [00:07<00:02, 8284.48it/s]\u001b[A\n",
      " 63%|██████▎   | 39216/62500 [00:07<00:02, 8613.32it/s]\u001b[A\n",
      " 64%|██████▍   | 40089/62500 [00:08<00:02, 8103.81it/s]\u001b[A\n",
      " 65%|██████▌   | 40914/62500 [00:08<00:02, 8040.01it/s]\u001b[A\n",
      " 67%|██████▋   | 41728/62500 [00:08<00:02, 7533.76it/s]\u001b[A\n",
      " 68%|██████▊   | 42495/62500 [00:08<00:02, 7146.88it/s]\u001b[A\n",
      " 69%|██████▉   | 43255/62500 [00:08<00:02, 7276.75it/s]\u001b[A\n",
      " 71%|███████   | 44192/62500 [00:08<00:02, 7799.00it/s]\u001b[A\n",
      " 72%|███████▏  | 44990/62500 [00:08<00:02, 7745.92it/s]\u001b[A\n",
      " 74%|███████▎  | 45992/62500 [00:08<00:01, 8310.94it/s]\u001b[A\n",
      " 75%|███████▍  | 46865/62500 [00:08<00:01, 8432.33it/s]\u001b[A\n",
      " 76%|███████▋  | 47724/62500 [00:09<00:01, 8474.27it/s]\u001b[A\n",
      " 78%|███████▊  | 48582/62500 [00:09<00:01, 8376.47it/s]\u001b[A\n",
      " 79%|███████▉  | 49428/62500 [00:09<00:01, 8056.22it/s]\u001b[A\n",
      " 80%|████████  | 50252/62500 [00:09<00:01, 8107.91it/s]\u001b[A\n",
      " 82%|████████▏ | 51069/62500 [00:09<00:01, 8116.48it/s]\u001b[A\n",
      " 83%|████████▎ | 51885/62500 [00:09<00:01, 7808.10it/s]\u001b[A\n",
      " 84%|████████▍ | 52749/62500 [00:09<00:01, 8040.03it/s]\u001b[A\n",
      " 86%|████████▌ | 53669/62500 [00:09<00:01, 8354.08it/s]\u001b[A\n",
      " 87%|████████▋ | 54550/62500 [00:09<00:00, 8484.96it/s]\u001b[A\n",
      " 89%|████████▊ | 55404/62500 [00:09<00:00, 8310.78it/s]\u001b[A\n",
      " 90%|█████████ | 56277/62500 [00:10<00:00, 8430.30it/s]\u001b[A\n",
      " 92%|█████████▏| 57216/62500 [00:10<00:00, 8696.21it/s]\u001b[A\n",
      " 93%|█████████▎| 58117/62500 [00:10<00:00, 8787.75it/s]\u001b[A\n",
      " 94%|█████████▍| 59048/62500 [00:10<00:00, 8935.64it/s]\u001b[A\n",
      " 96%|█████████▌| 59945/62500 [00:10<00:00, 8818.87it/s]\u001b[A\n",
      " 98%|█████████▊| 60938/62500 [00:10<00:00, 9118.16it/s]\u001b[A\n",
      " 99%|█████████▉| 61919/62500 [00:10<00:00, 9313.76it/s]\u001b[A\n",
      "100%|██████████| 62500/62500 [00:10<00:00, 5819.59it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "train_encoded = encode_sentences_with_bow_encoder(train_texts, w2v_model, my_tokenizer)\n",
    "test_encoded = encode_sentences_with_bow_encoder(test_texts, w2v_model, my_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "assert isinstance(train_encoded, np.ndarray)\n",
    "assert isinstance(test_encoded, np.ndarray)\n",
    "\n",
    "assert train_encoded.shape[0] == len(train_texts)\n",
    "assert train_encoded.shape[1] == w2v_model.vector_size\n",
    "\n",
    "assert test_encoded.shape[0] == len(test_texts)\n",
    "assert test_encoded.shape[1] == w2v_model.vector_size\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.66      0.65     31237\n",
      "          1       0.65      0.62      0.64     31263\n",
      "\n",
      "avg / total       0.64      0.64      0.64     62500\n",
      "\n",
      "AUC = 0.6429359320639207\n"
     ]
    }
   ],
   "source": [
    "clf = LinearSVC()\n",
    "clf.fit(train_encoded, train_labels)\n",
    "preds = clf.predict(test_encoded)\n",
    "\n",
    "print(classification_report(test_labels, preds))\n",
    "print(\"AUC = {}\".format(roc_auc_score(test_labels, preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not too impressive!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you attempt to improve your encoder by filtering out stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bow_encoder_with_stopwords(wmodel, tokenizer, stopwords, text):\n",
    "    \n",
    "    zero_vector = np.zeros(w2v_model.vector_size)\n",
    "    \n",
    "    tokens = tokenizer(text)\n",
    "    \n",
    "    zero_vector = np.zeros(w2v_model.vector_size)\n",
    "    word_vectors = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token in wmodel and token.lower() not in stopwords:\n",
    "            word_vectors.append(wmodel[token])\n",
    "    if len(word_vectors):\n",
    "        sent_vector = np.mean(word_vectors, axis=0)\n",
    "    else:\n",
    "        sent_vector = zero_vector\n",
    "        \n",
    "    return sent_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stops = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187500/187500 [00:16<00:00, 11398.73it/s]\n",
      "100%|██████████| 62500/62500 [00:05<00:00, 12188.47it/s]\n"
     ]
    }
   ],
   "source": [
    "train_encoded = \n",
    "test_encoded = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = LinearSVC()\n",
    "clf.fit(train_encoded, train_labels)\n",
    "preds = clf.predict(test_encoded)\n",
    "\n",
    "print(classification_report(test_labels, preds))\n",
    "print(\"AUC = {}\".format(roc_auc_score(test_labels, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looks like the BoW model is not too good for the job!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![architecture](pics/we_need_to_go_deeper.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing: Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras is a cool library built on top of the computational backend provided by Tensorflow. It provides a layer of abstraction between you and complicated tensor algebra, allowing for rapid prototyping of deep neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.1: Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start crunching word vectors with convolutional neural networks, we need to prepare our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the vocabulary we created earlier\n",
    "voc, rvoc = pickle.load(open(\"../dict_rdict.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we are going to use the whole dataset this time around\n",
    "texts = sentiment_data['message'].tolist()\n",
    "labels = np.array(sentiment_data['sentiment'])\n",
    "\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the function that turns tokens into their ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hint: you may want to use the function you've built during seminar 2\n",
    "MAX_LEN = 32\n",
    "\n",
    "def vectorize_tokens(sentence, tokenizer, token_to_id, max_len):\n",
    "   \n",
    "    tokens = tokenizer(sentence)\n",
    "    ids = []    \n",
    "    for token in tokens:\n",
    "        ids.append(token_to_id.get(token, token_to_id[\"UNKN\"]))\n",
    "    if len(ids) < max_len:\n",
    "        ids += (max_len-len(ids))*[token_to_id[\"NULL\"]]\n",
    "    else:\n",
    "        ids = ids[:max_len]\n",
    "\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now apply the vectorization function to every sentence from train and test datasets. In the end you should end up with a matrix of shape [len(data), MAX_LEN].\n",
    "\n",
    "Just write a little loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize_sentences(sentences, tokenizer, token_to_id, max_len):\n",
    "    sentence_ids = []\n",
    "    \n",
    "    for sentence in tqdm(sentences):\n",
    "        sentence_ids.append(vectorize_tokens(sentence, tokenizer, token_to_id, max_len))\n",
    "        \n",
    "    return np.array(sentence_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/937500 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 139/937500 [00:00<18:13, 856.98it/s]\u001b[A\n",
      "  0%|          | 3783/937500 [00:00<12:50, 1212.03it/s]\u001b[A\n",
      "  1%|          | 6567/937500 [00:00<09:07, 1699.75it/s]\u001b[A\n",
      "  1%|          | 10158/937500 [00:00<06:29, 2379.94it/s]\u001b[A\n",
      "  2%|▏         | 14089/937500 [00:00<04:38, 3313.91it/s]\u001b[A\n",
      "  2%|▏         | 17287/937500 [00:00<03:23, 4532.83it/s]\u001b[A\n",
      "  2%|▏         | 20927/937500 [00:00<02:29, 6147.15it/s]\u001b[A\n",
      "  3%|▎         | 24025/937500 [00:00<01:54, 7955.00it/s]\u001b[A\n",
      "  3%|▎         | 26954/937500 [00:01<01:34, 9644.76it/s]\u001b[A\n",
      "  3%|▎         | 29578/937500 [00:01<01:16, 11896.31it/s]\u001b[A\n",
      "  3%|▎         | 32635/937500 [00:01<01:02, 14565.00it/s]\u001b[A\n",
      "  4%|▍         | 35387/937500 [00:01<00:53, 16765.90it/s]\u001b[A\n",
      "  4%|▍         | 38566/937500 [00:01<00:46, 19535.56it/s]\u001b[A\n",
      "  4%|▍         | 41634/937500 [00:01<00:40, 21924.32it/s]\u001b[A\n",
      "  5%|▍         | 45361/937500 [00:01<00:35, 25012.29it/s]\u001b[A\n",
      "  5%|▌         | 48518/937500 [00:01<00:37, 23949.29it/s]\u001b[A\n",
      "  5%|▌         | 51382/937500 [00:01<00:35, 25073.92it/s]\u001b[A\n",
      "  6%|▌         | 54873/937500 [00:01<00:32, 27388.12it/s]\u001b[A\n",
      "  6%|▌         | 58288/937500 [00:02<00:30, 29117.68it/s]\u001b[A\n",
      "  7%|▋         | 62207/937500 [00:02<00:27, 31549.57it/s]\u001b[A\n",
      "  7%|▋         | 65591/937500 [00:02<00:27, 31550.60it/s]\u001b[A\n",
      "  7%|▋         | 68906/937500 [00:02<00:27, 31681.88it/s]\u001b[A\n",
      "  8%|▊         | 72276/937500 [00:02<00:26, 32260.35it/s]\u001b[A\n",
      "  8%|▊         | 76081/937500 [00:02<00:25, 33802.42it/s]\u001b[A\n",
      "  8%|▊         | 79538/937500 [00:03<00:56, 15091.65it/s]\u001b[A\n",
      "  9%|▉         | 82842/937500 [00:03<00:47, 18028.87it/s]\u001b[A\n",
      "  9%|▉         | 86469/937500 [00:03<00:40, 21232.11it/s]\u001b[A\n",
      " 10%|▉         | 89595/937500 [00:03<00:36, 23492.48it/s]\u001b[A\n",
      " 10%|▉         | 93133/937500 [00:03<00:32, 26125.42it/s]\u001b[A\n",
      " 10%|█         | 96589/937500 [00:03<00:29, 28188.59it/s]\u001b[A\n",
      " 11%|█         | 99879/937500 [00:03<00:28, 29253.15it/s]\u001b[A\n",
      " 11%|█         | 103145/937500 [00:03<00:28, 29695.13it/s]\u001b[A\n",
      " 11%|█▏        | 106355/937500 [00:03<00:28, 29128.57it/s]\u001b[A\n",
      " 12%|█▏        | 109439/937500 [00:04<00:28, 29375.47it/s]\u001b[A\n",
      " 12%|█▏        | 112499/937500 [00:04<00:27, 29728.60it/s]\u001b[A\n",
      " 12%|█▏        | 115822/937500 [00:04<00:26, 30698.07it/s]\u001b[A\n",
      " 13%|█▎        | 118960/937500 [00:04<00:27, 30245.05it/s]\u001b[A\n",
      " 13%|█▎        | 122034/937500 [00:04<00:27, 29578.77it/s]\u001b[A\n",
      " 13%|█▎        | 125030/937500 [00:04<00:27, 29060.17it/s]\u001b[A\n",
      " 14%|█▎        | 127965/937500 [00:04<00:28, 28606.54it/s]\u001b[A\n",
      " 14%|█▍        | 130890/937500 [00:04<00:28, 28794.38it/s]\u001b[A\n",
      " 14%|█▍        | 134323/937500 [00:04<00:26, 30253.92it/s]\u001b[A\n",
      " 15%|█▍        | 137494/937500 [00:04<00:26, 30674.74it/s]\u001b[A\n",
      " 15%|█▍        | 140585/937500 [00:05<00:28, 27524.52it/s]\u001b[A\n",
      " 15%|█▌        | 143415/937500 [00:05<00:31, 25059.43it/s]\u001b[A\n",
      " 16%|█▌        | 146231/937500 [00:05<00:30, 25913.10it/s]\u001b[A\n",
      " 16%|█▌        | 149827/937500 [00:05<00:27, 28282.02it/s]\u001b[A\n",
      " 16%|█▋        | 152772/937500 [00:05<00:29, 26228.66it/s]\u001b[A\n",
      " 17%|█▋        | 156099/937500 [00:05<00:27, 28006.33it/s]\u001b[A\n",
      " 17%|█▋        | 159120/937500 [00:05<00:27, 28378.50it/s]\u001b[A\n",
      " 17%|█▋        | 162037/937500 [00:05<00:30, 25799.67it/s]\u001b[A\n",
      " 18%|█▊        | 164718/937500 [00:06<00:32, 23765.21it/s]\u001b[A\n",
      " 18%|█▊        | 167197/937500 [00:06<00:32, 23741.87it/s]\u001b[A\n",
      " 18%|█▊        | 170239/937500 [00:06<00:30, 25409.80it/s]\u001b[A\n",
      " 19%|█▊        | 173505/937500 [00:06<00:28, 27221.31it/s]\n",
      "100%|██████████| 937500/937500 [00:39<00:00, 23724.34it/s]\n",
      "100%|██████████| 312500/312500 [00:12<00:00, 25488.08it/s]\n"
     ]
    }
   ],
   "source": [
    "train_vectorized = vectorize_sentences(train_texts, my_tokenizer, voc, MAX_LEN)\n",
    "test_vectorized = vectorize_sentences(test_texts, my_tokenizer, voc, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "assert isinstance(train_vectorized, np.ndarray)\n",
    "assert isinstance(test_vectorized, np.ndarray)\n",
    "\n",
    "assert train_vectorized.shape == (len(train_vectorized), MAX_LEN)\n",
    "assert test_vectorized.shape == (len(test_vectorized), MAX_LEN)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Building a deep NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings_matrix = w2v_model.syn0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras Input layer is basically the same thing as tf.placeholder\n",
    "# it defines a node where the network will be expecting to recieve input data\n",
    "input_layer = keras.layers.Input(shape=(MAX_LEN,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# keras Embedding layer is a container for dense vectors\n",
    "# it recieves a list of token identifiers of shape [MAX_LEN] \n",
    "# and turns it into a matrix of shape [MAX_LEN, EMBEDDING_DIM]\n",
    "\n",
    "embedding_layer = keras.layers.Embedding(embeddings_matrix.shape[0], embeddings_matrix.shape[1], \n",
    "                                         input_length=MAX_LEN, weights=[embeddings_matrix],\n",
    "                                         trainable=False)(input_layer)\n",
    "# notice how the input_layer is plugged into the embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# keras Convolutional layer implements a set of learnable filters\n",
    "# that extract local patterns from input data\n",
    "convolution_layer = keras.layers.Convolution1D(128, 3)(embedding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# keras GlobalMaxPooling layer applies a max filter to the input feature representation\n",
    "# only the strongest responses from the previous layer are kept, everything else is discarded\n",
    "subsampling_layer = keras.layers.GlobalMaxPooling1D()(convolution_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# keras Linear layers apply a simple linear transformation to input data, \n",
    "# which is optionally followed by a non-linear activation function\n",
    "# very useful for building Multi-Layer Perceptrons\n",
    "linear_layer_1 = keras.layers.Dense(64, activation='relu')(subsampling_layer)\n",
    "linear_layer_2 = keras.layers.Dense(1, activation='sigmoid')(linear_layer_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this compiles the computational graph we've just created, applies a loss function\n",
    "# and pre-computes the gradients for back propagation\n",
    "\n",
    "deep_model = keras.models.Model(inputs=[input_layer], outputs=[linear_layer_2])\n",
    "deep_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 32, 128)           6400000   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 30, 128)           49280     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 6,457,601\n",
      "Trainable params: 57,601\n",
      "Non-trainable params: 6,400,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "deep_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 937500 samples, validate on 312500 samples\n",
      "Epoch 1/1\n",
      "280128/937500 [=======>......................] - ETA: 10:28 - loss: 0.5366 - acc: 0.7256"
     ]
    }
   ],
   "source": [
    "deep_model.fit(x=train_vectorized, y=train_labels, batch_size=64, epochs=1, \n",
    "               validation_data=[test_vectorized, test_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = deep_model.predict(test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.865941180432684\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC = {}\".format(roc_auc_score(test_labels, preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thats more like it! Keep in mind that we only trained a tiny (57k parameters) model because of the limitations of CPU computing power. Using a deeper model with more trainable filters in the Convolution layer would likely result in even stronger predictive power. Stay tuned! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
